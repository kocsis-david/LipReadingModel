{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kocsis-david/LipReadingModel/blob/master/modeltrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "e8526b4b16525f50"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T18:58:32.488075Z",
     "start_time": "2024-05-11T18:58:31.785752Z"
    },
    "id": "fbc7b43538ee82ef"
   },
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def save_data(lips, Y, data_type):\n",
    "    with open(f'{data_type}_lips.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        header = ['label']\n",
    "        for i in range(lips[0].shape[0]): #frames\n",
    "            for j in range(lips[0].shape[1]): #height\n",
    "                for k in range(lips[0].shape[2]): #width\n",
    "                    header.append(f'pixel_{i}_{j}_{k}')\n",
    "        writer.writerow(header)\n",
    "        for i in range(len(lips)):\n",
    "            row = [Y[i].argmax()]\n",
    "            current_lips = lips[i].flatten()\n",
    "            for j in range(len(current_lips)):\n",
    "                row.append(current_lips[j])\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    X_train = pd.read_csv('/content/drive/MyDrive/lips/train_lips.csv')\n",
    "    Y_train = X_train['label']\n",
    "    del X_train['label']\n",
    "    X_valid = pd.read_csv('/content/drive/MyDrive/lips/valid_lips.csv')\n",
    "    Y_valid = X_valid['label']\n",
    "    del X_valid['label']\n",
    "\n",
    "    X_test = pd.read_csv('/content/drive/MyDrive/lips/test_lips.csv')\n",
    "    Y_test = X_test['label']\n",
    "    del X_test['label']\n",
    "    return X_train, Y_train, X_valid, Y_valid, X_test, Y_test"
   ],
   "id": "fbc7b43538ee82ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "870a25f5c0d0294",
    "outputId": "0617cc5e-b195-4bac-d0bb-7c283ebc8a6b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ],
   "id": "870a25f5c0d0294"
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJx7shFFHdQY",
    "outputId": "65f5f422-ef0b-4e86-9439-f73f995586ec"
   },
   "id": "NJx7shFFHdQY",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T19:01:07.132420Z",
     "start_time": "2024-05-11T18:58:36.625595Z"
    },
    "id": "b42e33a57438eef8"
   },
   "source": [
    "# loading the data from the csv files\n",
    "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = load_data()\n",
    "import numpy as np\n",
    "x_train = np.array(X_train, dtype='float32').reshape(-1, 11, 60, 100, 1)\n",
    "x_valid = np.array(X_valid, dtype='float32').reshape(-1, 11, 60, 100, 1)\n",
    "x_test = np.array(X_test, dtype='float32').reshape(-1, 11, 60, 100, 1)\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "Y_train_reshaped = np.array(Y_train).reshape(-1, 1)\n",
    "Y_valid_reshaped = np.array(Y_valid).reshape(-1, 1)\n",
    "Y_test_reshaped = np.array(Y_test).reshape(-1, 1)\n",
    "\n",
    "Y_train_onehot = onehot_encoder.fit_transform(Y_train_reshaped)\n",
    "Y_valid_onehot = onehot_encoder.fit_transform(Y_valid_reshaped)\n",
    "Y_test_onehot = onehot_encoder.fit_transform(Y_test_reshaped)\n",
    "\n",
    "# Convert one-hot encoded arrays to dense arrays\n",
    "Y_train = Y_train_onehot.toarray()\n",
    "Y_valid = Y_valid_onehot.toarray()\n",
    "Y_test = Y_test_onehot.toarray()\n"
   ],
   "id": "b42e33a57438eef8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T19:01:24.443651Z",
     "start_time": "2024-05-11T19:01:07.143086Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15332ddfeb1dcf15",
    "outputId": "d1e9ca42-5fc1-4e59-d55b-1ee7748b2dd2"
   },
   "source": [
    "mean=x_train.mean(axis=0)\n",
    "std=x_train.std(axis=0)\n",
    "\n",
    "X_train=np.array((x_train-mean)/std)\n",
    "x_train=None\n",
    "X_valid=np.array((x_valid-mean)/std)\n",
    "x_valid=None\n",
    "X_test=np.array((x_test-mean)/std)\n",
    "x_test=None\n",
    "\n",
    "print(X_train.shape)\n"
   ],
   "id": "15332ddfeb1dcf15",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4768, 11, 60, 100, 1)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T13:50:19.102575Z",
     "start_time": "2024-05-07T13:50:18.614440Z"
    },
    "id": "ed7b3b4637f1e",
    "outputId": "12f9a88a-3f82-4ee2-ba15-2f9802e1210f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 11, 60, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "b0_conv3d_1 (Conv3D)            (None, 11, 60, 100,  1152        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b0_relu_1 (ReLU)                (None, 11, 60, 100,  0           b0_conv3d_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b0_bn_1 (BatchNormalization)    (None, 11, 60, 100,  256         b0_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 5, 30, 50, 64 0           b0_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b1_cnv3d_1 (Conv3D)             (None, 3, 15, 25, 16 27648       max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_relu_1 (ReLU)                (None, 3, 15, 25, 16 0           b1_cnv3d_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b1_bn_1 (BatchNormalization)    (None, 3, 15, 25, 16 64          b1_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b1_cnv3d_2 (Conv3D)             (None, 2, 8, 13, 32) 512         b1_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b1_relu_2 (ReLU)                (None, 2, 8, 13, 32) 0           b1_cnv3d_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b1_out (BatchNormalization)     (None, 2, 8, 13, 32) 128         b1_relu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b2_cnv3d_1 (Conv3D)             (None, 2, 8, 13, 32) 1024        b1_out[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b2_relu_1 (ReLU)                (None, 2, 8, 13, 32) 0           b2_cnv3d_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b2_bn_1 (BatchNormalization)    (None, 2, 8, 13, 32) 128         b2_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 8, 13, 32) 0           b1_out[0][0]                     \n",
      "                                                                 b2_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b2_cnv3d_2 (Conv3D)             (None, 1, 4, 7, 64)  55296       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "b2_relu_2 (ReLU)                (None, 1, 4, 7, 64)  0           b2_cnv3d_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b2_bn_2 (BatchNormalization)    (None, 1, 4, 7, 64)  256         b2_relu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b3_cnv3d_1 (Conv3D)             (None, 1, 4, 7, 64)  4096        b2_bn_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b3_relu_1 (ReLU)                (None, 1, 4, 7, 64)  0           b3_cnv3d_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b3_bn_1 (BatchNormalization)    (None, 1, 4, 7, 64)  256         b3_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1, 4, 7, 64)  0           b2_bn_2[0][0]                    \n",
      "                                                                 b3_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b3_cnv3d_2 (Conv3D)             (None, 1, 2, 4, 128) 221184      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b3_relu_2 (ReLU)                (None, 1, 2, 4, 128) 0           b3_cnv3d_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b3_out (BatchNormalization)     (None, 1, 2, 4, 128) 512         b3_relu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 1, 2, 4, 32)  32800       b3_out[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1, 2, 4, 32)  0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 2, 4, 32)  0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1, 2, 4, 32)  0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d (SpatialDropo (None, 1, 2, 4, 32)  0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 1, 2, 4, 32)  4128        b3_out[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 1, 2, 4, 32)  1056        spatial_dropout3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1, 2, 4, 32)  0           conv3d_2[0][0]                   \n",
      "                                                                 conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 1, 2, 4, 32)  8224        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 2, 4, 32)  0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 2, 4, 32)  0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1, 2, 4, 32)  0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_1 (SpatialDro (None, 1, 2, 4, 32)  0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 1, 2, 4, 32)  1056        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 1, 2, 4, 32)  1056        spatial_dropout3d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 1, 2, 4, 32)  0           conv3d_5[0][0]                   \n",
      "                                                                 conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 1, 2, 4, 32)  8224        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 2, 4, 32)  0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 2, 4, 32)  0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 1, 2, 4, 32)  0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout3d_2 (SpatialDro (None, 1, 2, 4, 32)  0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 1, 2, 4, 32)  1056        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 1, 2, 4, 32)  1056        spatial_dropout3d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 2, 4, 32)  0           conv3d_8[0][0]                   \n",
      "                                                                 conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1, 2, 4, 32)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_output (Dense)            (None, 6)            774         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6)            0           model_output[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 404,838\n",
      "Trainable params: 404,038\n",
      "Non-trainable params: 800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Input, \\\n",
    "    ReLU, GlobalAveragePooling3D, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "output_shape = 6\n",
    "input = Input(shape=(11, 60, 100, 1))\n",
    "\n",
    "'''block_0'''\n",
    "b0_conv3d_1 = Conv3D(64, kernel_size=(2, 3, 3), padding='same', use_bias=False,\n",
    "                     name='b0_conv3d_1', kernel_initializer='he_normal')(input)\n",
    "b0_relu_1 = ReLU(name='b0_relu_1')(b0_conv3d_1)\n",
    "b0_bn_1 = BatchNormalization(name='b0_bn_1')(b0_relu_1)\n",
    "b0_out = MaxPooling3D(pool_size=(2, 2, 2))(b0_bn_1)\n",
    "\n",
    "'''block_1'''\n",
    "b1_cnv3d_1 = Conv3D(filters=16, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b1_cnv3d_1', kernel_initializer='he_normal')(b0_out)\n",
    "b1_relu_1 = ReLU(name='b1_relu_1')(b1_cnv3d_1)\n",
    "b1_bn_1 = BatchNormalization(name='b1_bn_1')(b1_relu_1)  # size: 14*14\n",
    "\n",
    "b1_cnv3d_2 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=(2, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b1_cnv3d_2', kernel_initializer='he_normal')(b1_bn_1)\n",
    "b1_relu_2 = ReLU(name='b1_relu_2')(b1_cnv3d_2)\n",
    "b1_out = BatchNormalization(name='b1_out')(b1_relu_2)  # size: 14*14\n",
    "\n",
    "'''block 2'''\n",
    "b2_cnv3d_1 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_1', kernel_initializer='he_normal')(b1_out)\n",
    "b2_relu_1 = ReLU(name='b2_relu_1')(b2_cnv3d_1)\n",
    "b2_bn_1 = BatchNormalization(name='b2_bn_1')(b2_relu_1)  # size: 14*14\n",
    "\n",
    "b2_add = add([b1_out, b2_bn_1])  #\n",
    "\n",
    "b2_cnv3d_2 = Conv3D(filters=64, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_2', kernel_initializer='he_normal')(b2_add)\n",
    "b2_relu_2 = ReLU(name='b2_relu_2')(b2_cnv3d_2)\n",
    "b2_out = BatchNormalization(name='b2_bn_2')(b2_relu_2)  # size: 7*7\n",
    "\n",
    "'''block 3'''\n",
    "b3_cnv3d_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_1', kernel_initializer='he_normal')(b2_out)\n",
    "b3_relu_1 = ReLU(name='b3_relu_1')(b3_cnv3d_1)\n",
    "b3_bn_1 = BatchNormalization(name='b3_bn_1')(b3_relu_1)  # size: 7*7\n",
    "\n",
    "b3_add = add([b2_out, b3_bn_1])  #\n",
    "\n",
    "b3_cnv3d_2 = Conv3D(filters=128, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_2', kernel_initializer='he_normal')(b3_add)\n",
    "b3_relu_2 = ReLU(name='b3_relu_2')(b3_cnv3d_2)\n",
    "b3_out = BatchNormalization(name='b3_out')(b3_relu_2)  # size: 3*3\n",
    "\n",
    "'''block 4'''\n",
    "from tensorflow.keras.layers import Activation\n",
    "activation = 'wavenet'\n",
    "skip_connections = []\n",
    "use_skip_connections = False\n",
    "original_x = b3_out\n",
    "b4_tempconv1 = Conv3D(filters=32, kernel_size=(2,2,2),dilation_rate=(1,1,1), padding='same')(b3_out)\n",
    "if activation == 'norm_relu':\n",
    "    x = Activation('relu')(b4_tempconv1)\n",
    "    x = BatchNormalization(x)\n",
    "elif activation == 'wavenet':\n",
    "    tanh_out = Activation('tanh')(b4_tempconv1)\n",
    "    sigm_out = Activation('sigmoid')(b4_tempconv1)\n",
    "    x= tf.keras.layers.multiply([tanh_out, sigm_out])\n",
    "else:\n",
    "    x = Activation(activation)(b4_tempconv1)\n",
    "\n",
    "b4_spatialdropout1d =tf.keras.layers.SpatialDropout3D(0.2)(x)\n",
    "\n",
    "x = Conv3D(32, 1, padding='same')(b4_spatialdropout1d)\n",
    "original_x= Conv3D(32, 1, padding='same')(original_x)\n",
    "res_x = tf.keras.layers.add([original_x, x])\n",
    "skip_connections.append(x)\n",
    "\n",
    "original_x = res_x\n",
    "b4_tempconv1 = Conv3D(filters=32, kernel_size=(2,2,2),dilation_rate=(1,1,1), padding='same')(res_x)\n",
    "if activation == 'norm_relu':\n",
    "    x = Activation('relu')(b4_tempconv1)\n",
    "    x = BatchNormalization(x)\n",
    "elif activation == 'wavenet':\n",
    "    tanh_out = Activation('tanh')(b4_tempconv1)\n",
    "    sigm_out = Activation('sigmoid')(b4_tempconv1)\n",
    "    x= tf.keras.layers.multiply([tanh_out, sigm_out])\n",
    "else:\n",
    "    x = Activation(activation)(b4_tempconv1)\n",
    "\n",
    "b4_spatialdropout1d =tf.keras.layers.SpatialDropout3D(0.2)(x)\n",
    "\n",
    "x = Conv3D(32, 1, padding='same')(b4_spatialdropout1d)\n",
    "original_x= Conv3D(32, 1, padding='same')(original_x)\n",
    "res_x = tf.keras.layers.add([original_x, x])\n",
    "skip_connections.append(x)\n",
    "\n",
    "original_x = res_x\n",
    "b4_tempconv1 = Conv3D(filters=32, kernel_size=(2,2,2),dilation_rate=(1,1,1), padding='same')(res_x)\n",
    "if activation == 'norm_relu':\n",
    "    x = Activation('relu')(b4_tempconv1)\n",
    "    x = BatchNormalization(x)\n",
    "elif activation == 'wavenet':\n",
    "    tanh_out = Activation('tanh')(b4_tempconv1)\n",
    "    sigm_out = Activation('sigmoid')(b4_tempconv1)\n",
    "    x= tf.keras.layers.multiply([tanh_out, sigm_out])\n",
    "else:\n",
    "    x = Activation(activation)(b4_tempconv1)\n",
    "\n",
    "b4_spatialdropout1d =tf.keras.layers.SpatialDropout3D(0.2)(x)\n",
    "\n",
    "x = Conv3D(32, 1, padding='same')(b4_spatialdropout1d)\n",
    "original_x= Conv3D(32, 1, padding='same')(original_x)\n",
    "res_x = tf.keras.layers.add([original_x, x])\n",
    "skip_connections.append(x)\n",
    "\n",
    "if use_skip_connections:\n",
    "    res_x = tf.keras.layers.add(skip_connections)\n",
    "\n",
    "x=Activation('relu')(res_x)\n",
    "'''block 5'''\n",
    "\n",
    "#tcn_out=tf.keras.layers.MultiHeadAttention(num_heads=12, key_dim=2, value_dim=2)(tcn_out,tcn_out,tcn_out)\n",
    "\n",
    "flatten = Flatten()(x)\n",
    "last_layer = Dense(128, activation='relu')(flatten)\n",
    "output = Dense(output_shape, name='model_output', activation=None,\n",
    "               kernel_initializer='he_uniform')(last_layer)\n",
    "output = Activation('softmax')(output)\n",
    "model = Model(input, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ],
   "id": "ed7b3b4637f1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T13:50:38.282268Z",
     "start_time": "2024-05-07T13:50:21.164797Z"
    },
    "id": "7dd9e7be66c54d57",
    "outputId": "e2723b92-28e3-411a-cdcd-6e0f2ba2de07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4768 samples, validate on 241 samples\n",
      "Epoch 1/30\n",
      "4768/4768 [==============================] - 26s 6ms/sample - loss: 1.5952 - accuracy: 0.3440 - val_loss: 1.4133 - val_accuracy: 0.4149\n",
      "Epoch 2/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 1.1403 - accuracy: 0.5495 - val_loss: 1.2267 - val_accuracy: 0.5062\n",
      "Epoch 3/30\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.9173 - accuracy: 0.6518 - val_loss: 1.2214 - val_accuracy: 0.5311\n",
      "Epoch 4/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.7604 - accuracy: 0.7125 - val_loss: 1.2177 - val_accuracy: 0.5436\n",
      "Epoch 5/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.6459 - accuracy: 0.7513 - val_loss: 1.1900 - val_accuracy: 0.5934\n",
      "Epoch 6/30\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.5695 - accuracy: 0.7785 - val_loss: 1.3767 - val_accuracy: 0.5768\n",
      "Epoch 7/30\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.4526 - accuracy: 0.8312 - val_loss: 1.2944 - val_accuracy: 0.5436\n",
      "Epoch 8/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.3978 - accuracy: 0.8429 - val_loss: 1.5086 - val_accuracy: 0.5519\n",
      "Epoch 9/30\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.3330 - accuracy: 0.8698 - val_loss: 1.6983 - val_accuracy: 0.5394\n",
      "Epoch 10/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.2756 - accuracy: 0.8953 - val_loss: 1.6764 - val_accuracy: 0.5726\n",
      "Epoch 11/30\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.2481 - accuracy: 0.9090 - val_loss: 1.9162 - val_accuracy: 0.5311\n",
      "Epoch 12/30\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.2166 - accuracy: 0.9146 - val_loss: 2.0565 - val_accuracy: 0.5809\n",
      "Epoch 13/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1937 - accuracy: 0.9316 - val_loss: 1.8164 - val_accuracy: 0.5726\n",
      "Epoch 14/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.2138 - accuracy: 0.9216 - val_loss: 1.8592 - val_accuracy: 0.5851\n",
      "Epoch 15/30\n",
      "4736/4768 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9462Restoring model weights from the end of the best epoch.\n",
      "4768/4768 [==============================] - 24s 5ms/sample - loss: 0.1525 - accuracy: 0.9459 - val_loss: 2.0532 - val_accuracy: 0.5892\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa857344dd8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, patience=10, restore_best_weights=True,\n",
    "                                      min_delta=0.001)\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=30, verbose=1, validation_data=(X_valid, Y_valid,), callbacks=[es])"
   ],
   "id": "7dd9e7be66c54d57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89e56074307f5efb",
    "outputId": "b41d1238-b0d1-4805-9beb-ec6654b65391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.42      0.48        50\n",
      "           1       0.68      0.69      0.68        36\n",
      "           2       0.52      0.54      0.53        50\n",
      "           3       0.41      0.50      0.45        28\n",
      "           4       0.62      0.62      0.62        50\n",
      "           5       0.41      0.45      0.43        31\n",
      "\n",
      "    accuracy                           0.54       245\n",
      "   macro avg       0.53      0.54      0.53       245\n",
      "weighted avg       0.54      0.54      0.54       245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(classification_report(np.argmax(Y_test,1),np.argmax(preds,1)))"
   ],
   "id": "89e56074307f5efb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T23:31:39.893673Z",
     "start_time": "2024-05-07T23:31:39.032191Z"
    },
    "id": "9abaee088ac40a42",
    "outputId": "a89e21c9-5306-4be7-f2ed-fa499412d396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 11, 60, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "b0_conv3d_1 (Conv3D)            (None, 11, 60, 100,  1152        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b0_relu_1 (ReLU)                (None, 11, 60, 100,  0           b0_conv3d_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b0_bn_1 (BatchNormalization)    (None, 11, 60, 100,  256         b0_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 5, 30, 50, 64 0           b0_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b1_cnv3d_1 (Conv3D)             (None, 3, 15, 25, 16 27648       max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b1_relu_1 (ReLU)                (None, 3, 15, 25, 16 0           b1_cnv3d_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b1_bn_1 (BatchNormalization)    (None, 3, 15, 25, 16 64          b1_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b1_cnv3d_2 (Conv3D)             (None, 2, 8, 13, 32) 512         b1_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b1_relu_2 (ReLU)                (None, 2, 8, 13, 32) 0           b1_cnv3d_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b1_out (BatchNormalization)     (None, 2, 8, 13, 32) 128         b1_relu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b2_cnv3d_1 (Conv3D)             (None, 2, 8, 13, 32) 1024        b1_out[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "b2_relu_1 (ReLU)                (None, 2, 8, 13, 32) 0           b2_cnv3d_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b2_bn_1 (BatchNormalization)    (None, 2, 8, 13, 32) 128         b2_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2, 8, 13, 32) 0           b1_out[0][0]                     \n",
      "                                                                 b2_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b2_cnv3d_2 (Conv3D)             (None, 1, 4, 7, 64)  55296       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "b2_relu_2 (ReLU)                (None, 1, 4, 7, 64)  0           b2_cnv3d_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b2_bn_2 (BatchNormalization)    (None, 1, 4, 7, 64)  256         b2_relu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "b3_cnv3d_1 (Conv3D)             (None, 1, 4, 7, 64)  4096        b2_bn_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b3_relu_1 (ReLU)                (None, 1, 4, 7, 64)  0           b3_cnv3d_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b3_bn_1 (BatchNormalization)    (None, 1, 4, 7, 64)  256         b3_relu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1, 4, 7, 64)  0           b2_bn_2[0][0]                    \n",
      "                                                                 b3_bn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b3_cnv3d_2 (Conv3D)             (None, 1, 2, 4, 128) 221184      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "b3_relu_2 (ReLU)                (None, 1, 2, 4, 128) 0           b3_cnv3d_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "b3_out (BatchNormalization)     (None, 1, 2, 4, 128) 512         b3_relu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "my_layer_2 (MyLayer)            (None, 8, 128)       0           b3_out[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 1024)         4722688     my_layer_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          131200      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_output (Dense)            (None, 6)            774         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,167,174\n",
      "Trainable params: 5,166,374\n",
      "Non-trainable params: 800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling3D, Flatten,LSTM, Reshape, Dense, Dropout, BatchNormalization, Input, ReLU, GlobalAveragePooling2D, add\n",
    "from keras.models import Model\n",
    "\n",
    "output_shape = 2\n",
    "input = Input(shape=(11, 60, 100, 1))\n",
    "\n",
    "'''block_0'''\n",
    "b0_conv3d_1 = Conv3D(64, kernel_size=(2, 3, 3), padding='same', use_bias=False,\n",
    "                     name='b0_conv3d_1', kernel_initializer = 'he_normal')(input)\n",
    "b0_relu_1 = ReLU(name='b0_relu_1')(b0_conv3d_1)\n",
    "b0_bn_1 = BatchNormalization(name='b0_bn_1')(b0_relu_1)\n",
    "b0_out =  MaxPooling3D(pool_size=(1, 2, 2))(b0_bn_1)\n",
    "\n",
    "'''block_1'''\n",
    "b1_cnv3d_1 = Conv3D(filters=16, kernel_size=(1, 2, 2), strides=(1, 1, 1), padding='same',\n",
    "                        use_bias=False, name='b1_cnv3d_1', kernel_initializer=HeNormal())(b0_out)\n",
    "b1_relu_1 = ReLU(name='b1_relu_1')(b1_cnv3d_1)\n",
    "b1_bn_1 = BatchNormalization(name='b1_bn_1')(b1_relu_1)  # size: 14*14\n",
    "\n",
    "b1_cnv3d_2 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b1_cnv3d_2', kernel_initializer=HeNormal())(b1_bn_1)\n",
    "b1_relu_2 = ReLU(name='b1_relu_2')(b1_cnv3d_2)\n",
    "b1_out = BatchNormalization(name='b1_out')(b1_relu_2)  # size: 14*14\n",
    "\n",
    "\n",
    "'''block 2'''\n",
    "b2_cnv3d_1 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_1', kernel_initializer=HeNormal())(b1_out)\n",
    "b2_relu_1 = ReLU(name='b2_relu_1')(b2_cnv3d_1)\n",
    "b2_bn_1 = BatchNormalization(name='b2_bn_1')(b2_relu_1)  \n",
    "\n",
    "b2_add = add([b1_out, b2_bn_1])  #\n",
    "\n",
    "b2_cnv3d_2 = Conv3D(filters=64, kernel_size=(3, 3, 3), strides=(1, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_2', kernel_initializer=HeNormal())(b2_add)\n",
    "b2_relu_2 = ReLU(name='b2_relu_2')(b2_cnv3d_2)\n",
    "b2_out = BatchNormalization(name='b2_bn_2')(b2_relu_2)  # size: 7*7\n",
    "\n",
    "'''block 3'''\n",
    "b3_cnv3d_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_1', kernel_initializer=HeNormal())(b2_out)\n",
    "b3_relu_1 = ReLU(name='b3_relu_1')(b3_cnv3d_1)\n",
    "b3_bn_1 = BatchNormalization(name='b3_bn_1')(b3_relu_1)  # size: 7*7\n",
    "\n",
    "b3_add = add([b2_out, b3_bn_1])  #\n",
    "\n",
    "b3_cnv3d_2 = Conv3D(filters=128, kernel_size=(2, 2, 2), strides=(1, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_2', kernel_initializer=HeNormal())(b3_add)\n",
    "b3_relu_2 = ReLU(name='b3_relu_2')(b3_cnv3d_2)\n",
    "b3_out = BatchNormalization(name='b3_out')(b3_relu_2)  # size: 3*3\n",
    "\n",
    "\n",
    "'''block 4'''\n",
    "# b4_avg_p = GlobalAveragePooling2D()(b3_out)\n",
    "b4_flatten = Flatten()(b3_out)\n",
    "b4_reshape = Reshape(target_shape=(11, -1))(b4_flatten)\n",
    "\n",
    "'''lstm'''\n",
    "lstm = LSTM(units = 256, name='lstm')(b4_reshape)\n",
    "dropout = Dropout(rate = 0.4, name='dropout')(lstm)\n",
    "dense_1 = Dense(units = 128, name='dense_1')(dropout)\n",
    "\n",
    "\n",
    "output = Dense(output_shape, name='model_output', activation='softmax',\n",
    "                       kernel_initializer='he_uniform')(dense_1)\n",
    "\n",
    "model = Model(input, output)"
   ],
   "id": "9abaee088ac40a42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T23:27:51.780559Z",
     "start_time": "2024-05-07T23:27:31.309554Z"
    },
    "id": "1646fa35617625ce",
    "outputId": "a3a288e3-858b-4401-e545-bdf6890e48f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4768 samples, validate on 241 samples\n",
      "Epoch 1/30\n",
      "4768/4768 [==============================] - 32s 7ms/sample - loss: 1.5266 - accuracy: 0.3563 - val_loss: 1.4923 - val_accuracy: 0.3776\n",
      "Epoch 2/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 1.2260 - accuracy: 0.5113 - val_loss: 1.3212 - val_accuracy: 0.4606\n",
      "Epoch 3/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 1.0550 - accuracy: 0.5866 - val_loss: 1.0830 - val_accuracy: 0.5643\n",
      "Epoch 4/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.9201 - accuracy: 0.6420 - val_loss: 1.1174 - val_accuracy: 0.5477\n",
      "Epoch 5/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.8087 - accuracy: 0.6883 - val_loss: 1.1355 - val_accuracy: 0.5768\n",
      "Epoch 6/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.6931 - accuracy: 0.7341 - val_loss: 1.1277 - val_accuracy: 0.6183\n",
      "Epoch 7/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.6115 - accuracy: 0.7615 - val_loss: 1.0939 - val_accuracy: 0.5975\n",
      "Epoch 8/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.5633 - accuracy: 0.7846 - val_loss: 1.1293 - val_accuracy: 0.5809\n",
      "Epoch 9/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.4813 - accuracy: 0.8119 - val_loss: 1.1952 - val_accuracy: 0.6307\n",
      "Epoch 10/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.4326 - accuracy: 0.8234 - val_loss: 1.5338 - val_accuracy: 0.5768\n",
      "Epoch 11/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.3885 - accuracy: 0.8465 - val_loss: 1.4644 - val_accuracy: 0.5975\n",
      "Epoch 12/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.3720 - accuracy: 0.8500 - val_loss: 1.2215 - val_accuracy: 0.6390\n",
      "Epoch 13/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.2934 - accuracy: 0.8836 - val_loss: 1.3234 - val_accuracy: 0.5934\n",
      "Epoch 14/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.2910 - accuracy: 0.8849 - val_loss: 1.6542 - val_accuracy: 0.5934\n",
      "Epoch 15/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.2222 - accuracy: 0.9098 - val_loss: 1.7505 - val_accuracy: 0.5934\n",
      "Epoch 16/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.2234 - accuracy: 0.9132 - val_loss: 1.7057 - val_accuracy: 0.5892\n",
      "Epoch 17/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1821 - accuracy: 0.9333 - val_loss: 1.4790 - val_accuracy: 0.6349\n",
      "Epoch 18/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1469 - accuracy: 0.9457 - val_loss: 1.8315 - val_accuracy: 0.5643\n",
      "Epoch 19/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1191 - accuracy: 0.9532 - val_loss: 1.6811 - val_accuracy: 0.5477\n",
      "Epoch 20/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1370 - accuracy: 0.9522 - val_loss: 1.7028 - val_accuracy: 0.5975\n",
      "Epoch 21/30\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1120 - accuracy: 0.9606 - val_loss: 1.9448 - val_accuracy: 0.5602\n",
      "Epoch 22/30\n",
      "4736/4768 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.9647Restoring model weights from the end of the best epoch.\n",
      "4768/4768 [==============================] - 25s 5ms/sample - loss: 0.1074 - accuracy: 0.9646 - val_loss: 1.7381 - val_accuracy: 0.6141\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa877098160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, patience=10, restore_best_weights=True,\n",
    "                                      min_delta=0.001)\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=30, verbose=1, validation_data=(X_valid, Y_valid,), callbacks=[es])"
   ],
   "id": "1646fa35617625ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5f40abf5c43f40f",
    "outputId": "980bd59d-a6fd-41c1-faa5-44c238c5c924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59        50\n",
      "           1       0.65      0.61      0.63        36\n",
      "           2       0.69      0.40      0.51        50\n",
      "           3       0.52      0.54      0.53        28\n",
      "           4       0.67      0.66      0.67        50\n",
      "           5       0.46      0.58      0.51        31\n",
      "\n",
      "    accuracy                           0.58       245\n",
      "   macro avg       0.59      0.58      0.57       245\n",
      "weighted avg       0.60      0.58      0.58       245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(classification_report(np.argmax(Y_test,1),np.argmax(preds,1)))"
   ],
   "id": "b5f40abf5c43f40f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Input, \\\n",
    "    ReLU, GlobalAveragePooling3D, add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "output_shape = 6\n",
    "input = Input(shape=(11, 60, 100, 1))\n",
    "\n",
    "'''block_0'''\n",
    "b0_conv3d_1 = Conv3D(64, kernel_size=(2, 3, 3), padding='same', use_bias=False,\n",
    "                     name='b0_conv3d_1', kernel_initializer='he_normal')(input)\n",
    "b0_relu_1 = ReLU(name='b0_relu_1')(b0_conv3d_1)\n",
    "b0_bn_1 = BatchNormalization(name='b0_bn_1')(b0_relu_1)\n",
    "\n",
    "class C2DResnet18(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(C2DResnet18, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x=inputs\n",
    "        for i in range(2):\n",
    "            x = Conv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                    use_bias=False, name=f'b0_conv3d_{i}', kernel_initializer='he_normal')(x)\n",
    "            x = ReLU(name=f'b0_relu_{i}')(x)\n",
    "            x = BatchNormalization(name=f'b0_bn_{i}')(x)\n",
    "            x = Conv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                    use_bias=False, name=f'b0_conv3d_{i}', kernel_initializer='he_normal')(x)\n",
    "            x = ReLU(name=f'b0_relu_{i}')(x)\n",
    "            x = BatchNormalization(name=f'b0_bn_{i}')(x)\n",
    "            x = add([inputs, x])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "'''block 2'''\n",
    "b2_cnv3d_1 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_1', kernel_initializer='he_normal')(b1_out)\n",
    "b2_relu_1 = ReLU(name='b2_relu_1')(b2_cnv3d_1)\n",
    "b2_bn_1 = BatchNormalization(name='b2_bn_1')(b2_relu_1)  # size: 14*14\n",
    "\n",
    "b2_add = add([b1_out, b2_bn_1])  #\n",
    "\n",
    "b2_cnv3d_2 = Conv3D(filters=64, kernel_size=(3, 3, 3), strides=(1, 2, 2),padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_2', kernel_initializer='he_normal')(b2_add)\n",
    "b2_relu_2 = ReLU(name='b2_relu_2')(b2_cnv3d_2)\n",
    "b2_out = BatchNormalization(name='b2_bn_2')(b2_relu_2)  # size: 7*7\n",
    "\n",
    "'''block 3'''\n",
    "b3_cnv3d_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_1', kernel_initializer='he_normal')(b2_out)\n",
    "b3_relu_1 = ReLU(name='b3_relu_1')(b3_cnv3d_1)\n",
    "b3_bn_1 = BatchNormalization(name='b3_bn_1')(b3_relu_1)  # size: 7*7\n",
    "\n",
    "b3_add = add([b2_out, b3_bn_1])  #\n",
    "\n",
    "b3_cnv3d_2 = Conv3D(filters=128, kernel_size=(3, 3, 3), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_2', kernel_initializer='he_normal')(b3_add)\n",
    "b3_relu_2 = ReLU(name='b3_relu_2')(b3_cnv3d_2)\n",
    "b3_out = BatchNormalization(name='b3_out')(b3_relu_2)  # size: 3*3\n",
    "\n",
    "'''block 4'''\n",
    "\n",
    "b4_cnv3d_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_1', kernel_initializer='he_normal')(b3_out)\n",
    "b4_relu_1 = ReLU(name='b3_relu_1')(b3_cnv3d_1)\n",
    "b4_bn_1 = BatchNormalization(name='b3_bn_1')(b3_relu_1)  # size: 7*7\n",
    "\n",
    "b4_add = add([b2_out, b3_bn_1])  #\n",
    "\n",
    "b4_cnv3d_2 = Conv3D(filters=128, kernel_size=(3, 3, 3), strides=(1, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_2', kernel_initializer='he_normal')(b3_add)\n",
    "b4_relu_2 = ReLU(name='b3_relu_2')(b3_cnv3d_2)\n",
    "b4_out = BatchNormalization(name='b3_out')(b3_relu_2)\n",
    "\n",
    "\n",
    "class MyLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Perform your TensorFlow operations here\n",
    "        # For example, let's say tf_fn is a function that reshapes the input tensor\n",
    "        output = tf.reshape(inputs, (-1,11, 30*512))  # Replace with your desired shape\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "reshaped=MyLayer()(b4_out)\n",
    "bi_lstm =tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512,return_sequences=True))(reshaped)\n",
    "dropout = tf.keras.layers.Dropout(0.5)(bi_lstm)\n",
    "bi_lstm2 =tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512))(reshaped)\n",
    "dropout2 = tf.keras.layers.Dropout(0.5)(bi_lstm2)\n",
    "last_layer = Dense(128, activation='relu')(dropout2)\n",
    "output = Dense(output_shape, name='model_output', activation='softmax',\n",
    "               kernel_initializer='he_uniform')(last_layer)\n",
    "model = Model(input, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ],
   "metadata": {
    "id": "f6e820e5ffe509f9"
   },
   "id": "f6e820e5ffe509f9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Input, \\\n",
    "    ReLU, GlobalAveragePooling3D, add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "output_shape = 6\n",
    "input = Input(shape=(11, 60, 100, 1))\n",
    "\n",
    "'''block_0'''\n",
    "b0_conv3d_1 = Conv3D(64, kernel_size=(2, 3, 3),strides=(1,2,3), padding='same', use_bias=False,\n",
    "                     name='b0_conv3d_1', kernel_initializer='he_normal')(input)\n",
    "b0_relu_1 = ReLU(name='b0_relu_1')(b0_conv3d_1)\n",
    "b0_bn_1 = BatchNormalization(name='b0_bn_1')(b0_relu_1)\n",
    "\n",
    "\n",
    "'''block_1'''\n",
    "b1_cnv3d_1 = Conv3D(filters=16, kernel_size=(3, 3, 3) ,padding='same',\n",
    "                    use_bias=False, name='b1_cnv3d_1', kernel_initializer='he_normal')(b0_bn_1)\n",
    "b1_relu_1 = ReLU(name='b1_relu_1')(b1_cnv3d_1)\n",
    "b1_bn_1 = BatchNormalization(name='b1_bn_1')(b1_relu_1)  # size: 14*14\n",
    "\n",
    "b1_cnv3d_2 = Conv3D(filters=32, kernel_size=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b1_cnv3d_2', kernel_initializer='he_normal')(b1_bn_1)\n",
    "b1_relu_2 = ReLU(name='b1_relu_2')(b1_cnv3d_2)\n",
    "b1_out = BatchNormalization(name='b1_out')(b1_relu_2)  # size: 14*14\n",
    "\n",
    "'''block 2'''\n",
    "b2_cnv3d_1 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_1', kernel_initializer='he_normal')(b1_out)\n",
    "b2_relu_1 = ReLU(name='b2_relu_1')(b2_cnv3d_1)\n",
    "b2_bn_1 = BatchNormalization(name='b2_bn_1')(b2_relu_1)  # size: 14*14\n",
    "\n",
    "b2_add = add([b1_out, b2_bn_1])  #\n",
    "\n",
    "b2_cnv3d_2 = Conv3D(filters=64, kernel_size=(3, 3, 3), strides=(1, 3, 4),padding='same',\n",
    "                    use_bias=False, name='b2_cnv3d_2', kernel_initializer='he_normal')(b2_add)\n",
    "b2_relu_2 = ReLU(name='b2_relu_2')(b2_cnv3d_2)\n",
    "b2_out = BatchNormalization(name='b2_out')(b2_relu_2)  # size: 7*7\n",
    "\n",
    "'''block 3'''\n",
    "b3_cnv3d_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_1', kernel_initializer='he_normal')(b2_out)\n",
    "b3_relu_1 = ReLU(name='b3_relu_1')(b3_cnv3d_1)\n",
    "b3_bn_1 = BatchNormalization(name='b3_bn_1')(b3_relu_1)  # size: 7*7\n",
    "\n",
    "b3_add = add([b2_out, b3_bn_1])  #\n",
    "\n",
    "b3_cnv3d_2 = Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same',\n",
    "                    use_bias=False, name='b3_cnv3d_2', kernel_initializer='he_normal')(b3_add)\n",
    "b3_relu_2 = ReLU(name='b3_relu_2')(b3_cnv3d_2)\n",
    "b3_out = BatchNormalization(name='b3_out')(b3_relu_2)  # size: 3*3\n",
    "\n",
    "'''block 4'''\n",
    "\n",
    "b4_cnv3d_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same',\n",
    "                    use_bias=False, name='b4_cnv3d_1', kernel_initializer='he_normal')(b3_out)\n",
    "b4_relu_1 = ReLU(name='b4_relu_1')(b4_cnv3d_1)\n",
    "b4_bn_1 = BatchNormalization(name='b4_bn_1')(b4_relu_1)  # size: 7*7\n",
    "\n",
    "b4_add = add([b3_out, b4_bn_1])  #\n",
    "\n",
    "b4_cnv3d_2 = Conv3D(filters=128, kernel_size=(3, 3, 3), strides=(1, 2, 2), padding='same',\n",
    "                    use_bias=False, name='b4_cnv3d_2', kernel_initializer='he_normal')(b4_add)\n",
    "b4_relu_2 = ReLU(name='b4_relu_2')(b4_cnv3d_2)\n",
    "b4_out = BatchNormalization(name='b4_out')(b4_relu_2)\n",
    "\n",
    "\n",
    "class Reshaper(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Reshaper, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Perform your TensorFlow operations here\n",
    "        # For example, let's say tf_fn is a function that reshapes the input tensor\n",
    "        output = tf.reshape(inputs, (-1,11,25*128))  # Replace with your desired shape\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class Expanddim(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Expanddim, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Perform your TensorFlow operations here\n",
    "        # For example, let's say tf_fn is a function that reshapes the input tensor\n",
    "        output = tf.expand_dims(inputs, axis=-1)  # Replace with your desired shape\n",
    "        return output\n",
    "\n",
    "class SEAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SEAttention, self).__init__(**kwargs)\n",
    "        self.lstm = tf.keras.layers.LSTM(512)\n",
    "        self.global_avg_pool = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='sigmoid')\n",
    "    def call(self, inputs):\n",
    "        # Perform your TensorFlow operations here\n",
    "        # For example, let's say tf_fn is a function that reshapes the input tensor\n",
    "        temp=self.lstm(inputs)\n",
    "        x=Expanddim()(temp)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        output = tf.keras.layers.multiply([temp, x])\n",
    "        return output\n",
    "\n",
    "class TemporalBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size, strides, dilation_rate, dropout, **kwargs):\n",
    "        super(TemporalBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=out_channels, kernel_size=kernel_size, strides=strides,\n",
    "                                            padding='causal', dilation_rate=dilation_rate, activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=out_channels, kernel_size=kernel_size, strides=strides,\n",
    "                                            padding='causal', dilation_rate=dilation_rate, activation='relu')\n",
    "        self.downsample = None\n",
    "        self.out_channels = out_channels\n",
    "        self.strides = strides\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def build(self, __input_shape):\n",
    "        in_channels = __input_shape[-1]\n",
    "        if in_channels != self.out_channels:\n",
    "            self.downsample = tf.keras.Sequential()\n",
    "            self.downsample.add(tf.keras.layers.Conv1D(filters=self.out_channels, kernel_size=1, strides=self.strides))\n",
    "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        in_channels = inputs.shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        if(x.shape[-1]==residual.shape[-1]):\n",
    "            x = x + residual\n",
    "        elif self.downsample is not None:\n",
    "            x = x + self.downsample(residual)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "reshaped=Reshaper()(b4_out)\n",
    "\n",
    "temporal1=TemporalBlock(64, 4, 1, 2, 0.5)(reshaped)\n",
    "sea=SEAttention()(temporal1)\n",
    "upshape1=Expanddim()(sea)\n",
    "temporal2=TemporalBlock(128, 8, 1, 4, 0.5)(upshape1)\n",
    "sea2=SEAttention()(temporal2)\n",
    "upshape2=Expanddim()(sea2)\n",
    "temporal3=TemporalBlock(256, 8, 1, 8, 0.5)(upshape2)\n",
    "sea3=SEAttention()(temporal3)\n",
    "upshape3=Expanddim()(sea3)\n",
    "temporal4=TemporalBlock(128, 8, 1, 10, 0.5)(upshape3)\n",
    "\n",
    "output = Dense(output_shape, name='model_output', activation='softmax',\n",
    "               kernel_initializer='he_uniform')(sea2)\n",
    "model = Model(input, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T19:18:29.873199Z",
     "start_time": "2024-05-11T19:18:28.662618Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "508677260bb36f5e",
    "outputId": "9d6c9759-64a0-44fb-c419-5e63d477f9b5"
   },
   "id": "508677260bb36f5e",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 11, 60, 100, 1)]     0         []                            \n",
      "                                                                                                  \n",
      " b0_conv3d_1 (Conv3D)        (None, 11, 30, 34, 64)       1152      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " b0_relu_1 (ReLU)            (None, 11, 30, 34, 64)       0         ['b0_conv3d_1[0][0]']         \n",
      "                                                                                                  \n",
      " b0_bn_1 (BatchNormalizatio  (None, 11, 30, 34, 64)       256       ['b0_relu_1[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " b1_cnv3d_1 (Conv3D)         (None, 11, 30, 34, 16)       27648     ['b0_bn_1[0][0]']             \n",
      "                                                                                                  \n",
      " b1_relu_1 (ReLU)            (None, 11, 30, 34, 16)       0         ['b1_cnv3d_1[0][0]']          \n",
      "                                                                                                  \n",
      " b1_bn_1 (BatchNormalizatio  (None, 11, 30, 34, 16)       64        ['b1_relu_1[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " b1_cnv3d_2 (Conv3D)         (None, 11, 30, 34, 32)       512       ['b1_bn_1[0][0]']             \n",
      "                                                                                                  \n",
      " b1_relu_2 (ReLU)            (None, 11, 30, 34, 32)       0         ['b1_cnv3d_2[0][0]']          \n",
      "                                                                                                  \n",
      " b1_out (BatchNormalization  (None, 11, 30, 34, 32)       128       ['b1_relu_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " b2_cnv3d_1 (Conv3D)         (None, 11, 30, 34, 32)       1024      ['b1_out[0][0]']              \n",
      "                                                                                                  \n",
      " b2_relu_1 (ReLU)            (None, 11, 30, 34, 32)       0         ['b2_cnv3d_1[0][0]']          \n",
      "                                                                                                  \n",
      " b2_bn_1 (BatchNormalizatio  (None, 11, 30, 34, 32)       128       ['b2_relu_1[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 11, 30, 34, 32)       0         ['b1_out[0][0]',              \n",
      "                                                                     'b2_bn_1[0][0]']             \n",
      "                                                                                                  \n",
      " b2_cnv3d_2 (Conv3D)         (None, 11, 10, 9, 64)        55296     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " b2_relu_2 (ReLU)            (None, 11, 10, 9, 64)        0         ['b2_cnv3d_2[0][0]']          \n",
      "                                                                                                  \n",
      " b2_out (BatchNormalization  (None, 11, 10, 9, 64)        256       ['b2_relu_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " b3_cnv3d_1 (Conv3D)         (None, 11, 10, 9, 64)        4096      ['b2_out[0][0]']              \n",
      "                                                                                                  \n",
      " b3_relu_1 (ReLU)            (None, 11, 10, 9, 64)        0         ['b3_cnv3d_1[0][0]']          \n",
      "                                                                                                  \n",
      " b3_bn_1 (BatchNormalizatio  (None, 11, 10, 9, 64)        256       ['b3_relu_1[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 11, 10, 9, 64)        0         ['b2_out[0][0]',              \n",
      "                                                                     'b3_bn_1[0][0]']             \n",
      "                                                                                                  \n",
      " b3_cnv3d_2 (Conv3D)         (None, 11, 10, 9, 64)        110592    ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " b3_relu_2 (ReLU)            (None, 11, 10, 9, 64)        0         ['b3_cnv3d_2[0][0]']          \n",
      "                                                                                                  \n",
      " b3_out (BatchNormalization  (None, 11, 10, 9, 64)        256       ['b3_relu_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " b4_cnv3d_1 (Conv3D)         (None, 11, 10, 9, 64)        4096      ['b3_out[0][0]']              \n",
      "                                                                                                  \n",
      " b4_relu_1 (ReLU)            (None, 11, 10, 9, 64)        0         ['b4_cnv3d_1[0][0]']          \n",
      "                                                                                                  \n",
      " b4_bn_1 (BatchNormalizatio  (None, 11, 10, 9, 64)        256       ['b4_relu_1[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 11, 10, 9, 64)        0         ['b3_out[0][0]',              \n",
      "                                                                     'b4_bn_1[0][0]']             \n",
      "                                                                                                  \n",
      " b4_cnv3d_2 (Conv3D)         (None, 11, 5, 5, 128)        221184    ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " b4_relu_2 (ReLU)            (None, 11, 5, 5, 128)        0         ['b4_cnv3d_2[0][0]']          \n",
      "                                                                                                  \n",
      " b4_out (BatchNormalization  (None, 11, 5, 5, 128)        512       ['b4_relu_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " reshaper (Reshaper)         (None, 11, 3200)             0         ['b4_out[0][0]']              \n",
      "                                                                                                  \n",
      " temporal_block (TemporalBl  (None, 11, 64)               1040832   ['reshaper[0][0]']            \n",
      " ock)                                                                                             \n",
      "                                                                                                  \n",
      " se_attention (SEAttention)  (None, 512)                  1445376   ['temporal_block[0][0]']      \n",
      "                                                                                                  \n",
      " expanddim (Expanddim)       (None, 512, 1)               0         ['se_attention[0][0]']        \n",
      "                                                                                                  \n",
      " temporal_block_1 (Temporal  (None, 512, 128)             133120    ['expanddim[0][0]']           \n",
      " Block)                                                                                           \n",
      "                                                                                                  \n",
      " se_attention_1 (SEAttentio  (None, 512)                  1576448   ['temporal_block_1[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " model_output (Dense)        (None, 6)                    3078      ['se_attention_1[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4626566 (17.65 MB)\n",
      "Trainable params: 4625126 (17.64 MB)\n",
      "Non-trainable params: 1440 (5.62 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-11T19:18:34.028332Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "8dcd962735c71e8e",
    "outputId": "488c9d77-e556-4683-b4cb-4ddde2a415b3"
   },
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, patience=10, restore_best_weights=True,\n",
    "                                      min_delta=0.001)\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=30, verbose=1, validation_data=(X_valid, Y_valid,), callbacks=[es])"
   ],
   "id": "8dcd962735c71e8e",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      " 19/149 [==>...........................] - ETA: 6:49 - loss: 0.7514 - accuracy: 0.7023"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-2a9c09f3dda7>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, patience=10, restore_best_weights=True,\n\u001B[1;32m      2\u001B[0m                                       min_delta=0.001)\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_valid\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mes\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1805\u001B[0m                         ):\n\u001B[1;32m   1806\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1807\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1808\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1809\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    831\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 832\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    833\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    834\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    866\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    867\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 868\u001B[0;31m       return tracing_compilation.call_function(\n\u001B[0m\u001B[1;32m    869\u001B[0m           \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_no_variable_creation_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    870\u001B[0m       )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001B[0m in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m   \u001B[0mbound_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m   \u001B[0mflat_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munpack_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbound_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m    140\u001B[0m       \u001B[0mflat_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m   )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1321\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1322\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1323\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inference_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_preflattened\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1324\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001B[0m in \u001B[0;36mcall_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mcall_preflattened\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSequence\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m     \u001B[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 216\u001B[0;31m     \u001B[0mflat_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_flat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    217\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpack_output\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflat_outputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001B[0m in \u001B[0;36mcall_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mrecord\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop_recording\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    250\u001B[0m           \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_bound_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 251\u001B[0;31m             outputs = self._bound_context.call_function(\n\u001B[0m\u001B[1;32m    252\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    253\u001B[0m                 \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001B[0m in \u001B[0;36mcall_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m     \u001B[0mcancellation_context\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcancellation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1485\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcancellation_context\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1486\u001B[0;31m       outputs = execute.execute(\n\u001B[0m\u001B[1;32m   1487\u001B[0m           \u001B[0mname\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"utf-8\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1488\u001B[0m           \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     54\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eval"
   ],
   "metadata": {
    "id": "N72MBjuFkJs4"
   },
   "id": "N72MBjuFkJs4"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(classification_report(np.argmax(Y_test,1),np.argmax(preds,1)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G22Pjf0rdQUp",
    "outputId": "e9b4d65d-1606-48ce-df1f-a96e1247d9ba"
   },
   "id": "G22Pjf0rdQUp",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8/8 [==============================] - 7s 706ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65        50\n",
      "           1       0.68      0.78      0.73        36\n",
      "           2       0.50      0.54      0.52        50\n",
      "           3       0.71      0.89      0.79        28\n",
      "           4       0.76      0.68      0.72        50\n",
      "           5       0.55      0.39      0.45        31\n",
      "\n",
      "    accuracy                           0.64       245\n",
      "   macro avg       0.64      0.65      0.64       245\n",
      "weighted avg       0.64      0.64      0.64       245\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "conf=confusion_matrix(np.argmax(Y_test,1),np.argmax(preds,1))\n",
    "sns.heatmap(conf, annot=True, fmt='d', vmax=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "C3Ci4p_fkPrb",
    "outputId": "a85693f0-de1d-4187-e858-f619299d7c92"
   },
   "id": "C3Ci4p_fkPrb",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "metadata": {},
     "execution_count": 12
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGiCAYAAABzmGX7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAyElEQVR4nO3deVhUZf8G8HtYHGAEFNkVBJdUXHANMaxUytRcyrVc0FxKcSUzqRS3xNTcEve9JJdSU/slL+EWCYqQuCsuKahsIiAUI8v8/uB9R8+oGTUzz8i5P+91rqt55szh5rwDfP0+zzmj0Gg0GhARERH9l5noAERERGRaWBwQERGRBIsDIiIikmBxQERERBIsDoiIiEiCxQERERFJsDggIiIiCRYHREREJMHigIiIiCRYHBAREZEEiwMiIiITcfToUXTv3h3u7u5QKBTYs2eP5HmNRoPp06fDzc0N1tbWCAwMREpKimSfnJwcDBw4EHZ2dqhWrRqGDx+OgoKCCuVgcUBERGQiCgsL4evri4iIiCc+P3/+fCxbtgyrVq3C8ePHoVKp0LlzZxQVFWn3GThwIM6dO4fo6Gjs378fR48exahRoyqUQ8EPXiIiIjI9CoUCu3fvRq9evQCUdw3c3d3x4YcfYvLkyQCAvLw8uLi4YNOmTRgwYAAuXLgAHx8fJCQkoHXr1gCAAwcOoGvXrkhLS4O7u/vf+trsHBARERmQWq1Gfn6+ZFOr1RU+zvXr15Geno7AwEDtmL29Pfz8/BAXFwcAiIuLQ7Vq1bSFAQAEBgbCzMwMx48f/9tfy6LC6QxkutdA0RFMwtzbh0VHMAnVrFSiI5gECzNz0RHIhOT8eV90BJPxQJ1m0OMXZ1/T27HCl2/BzJkzJWNhYWGYMWNGhY6Tnp4OAHBxcZGMu7i4aJ9LT0+Hs7Oz5HkLCws4ODho9/k7TKY4ICIiMhllpXo7VGhoKEJCQiRjSqVSb8c3BBYHREREBqRUKvVSDLi6ugIAMjIy4Obmph3PyMhA8+bNtftkZmZKXldSUoKcnBzt6/8OrjkgIiLSpSnT36Yn3t7ecHV1RUxMjHYsPz8fx48fh7+/PwDA398fubm5SExM1O5z8OBBlJWVwc/P729/LXYOiIiIdJXp7496RRQUFODKlSvax9evX8epU6fg4OAAT09PTJw4EXPmzEH9+vXh7e2NadOmwd3dXXtFQ6NGjfDGG29g5MiRWLVqFYqLizF27FgMGDDgb1+pALA4ICIieoxGj//ir4iTJ0+iQ4cO2sf/W6sQFBSETZs2YcqUKSgsLMSoUaOQm5uLgIAAHDhwAFZWVtrXbN26FWPHjkWnTp1gZmaG3r17Y9myZRXKYTL3OeDVCuV4tUI5Xq1Qjlcr0KN4tcJDhr5a4cHtc3o7VhX3xno7lrGwc0BERKRL0LSCqWBxQEREpEvQtIKp4NUKREREJMHOARERkS493gTpecTigIiISBenFYiIiIgeYueAiIhIF69WICIiokeJugmSqeC0AhEREUmwc0BERKSL0wpEREQkIfNpBRYHREREumR+nwOuOSAiIiIJdg6IiIh0cVqBiIiIJGS+IJHTCkRERCTBzgEREZEuTisQERGRBKcV5KPNoE4Y81M4PjmzDp+cWYeRu2ag/qu+AABrexW6zhiC8TELMO3iRoT8uhRdw4ZAaWstOLXxjP4gCFcux6Mg/yqOxe5Dm9bNRUcyuimh45Cdf1myxZ08IDqWEK5uzli++gucvxaH63d+w6Fff4Bv88aiYxkdz0O5gAA/7N61Eb9fP4kH6jT06NFZdCQyIFl1DvLv5CD6i224+3s6FAoFmvduj3fWhGBlt0+gUChg61IdUXMjkZlyC9VqOqL75+/B1qU6to9ZKjq6wfXt2wMLF4RhTPBUnEj4DePHjcD//bgVPk1eRlbWXdHxjOrC+cvo3WOo9nFJifyud7a3t8O+qEj8+stxDOwzCnfv5sC7Tm3k5uaLjmZUPA8PqVQ2OH36PDZt2o6dO9eJjmNwGo38fu4fJavi4FLMb5LHMQt3os2gQHi0qIekHUewffTDIuDezUzELNyB3ovHwMzcDGWllbvFNGnCSKxbH4nNW3YAAMYET0XXLp0wbOgAzF8QITidcZWUlCIzM1t0DKHGThyBW2l3MDH4U+3YzRu3BCYSg+fhoaioQ4iKOiQ6hvHIfM2BrKYVHqUwU6BJ97aoYq1EatKVJ+6jtLWBuuDPSl8YWFpaomXLZog5+It2TKPRIOZgLNq2bSUwmRh16tbG2Uu/4GRyDFatW4iatdxERzK6zl06IPnUOazdtBhnU2IRffR7DBzSV3Qso+N5ILmqcOcgOzsbGzZsQFxcHNLT0wEArq6uaNeuHYYOHQonJ6dnHkOtVkOtVkvGSjSlsFCYVzROhTk38MDIXTNgobTEgz+K8O37i5F15fF/CdhUr4pXx72Fk98eNHgm0RwdHWBhYYHMDOm/ljMzs9CwQV1BqcRIPJmMcaOn4krKdbi4OuGjqWOx/0Ak2rd9EwUFhaLjGY2nlweC3huA1RGbsHTRGjRv0QRzvvgExcUPsOPbH0THMxqeBxmT+YLEChUHCQkJ6Ny5M2xsbBAYGIgXXngBAJCRkYFly5Zh3rx5iIqKQuvWrf/yOOHh4Zg5c6Zk7GX7JnilWrMKxq+4u9duY2XXT6C0tUbjrn54+8sPsKH/HEmBoKxqjUEbP0LWlVs4tGSXwTOR6YiJPqr97/PnLiHxZDJOnT2Mnm91wdavvxOYzLjMzBRI/u0cwmcvAQCcPX0BDX3qY8iwAbL6o8jzIGMyn1aoUHEwbtw49O3bF6tWrYJCoZA8p9Fo8MEHH2DcuHGIi4v7y+OEhoYiJCREMjav6aiKRPnHSotLkXMjAwBw5+zvqNmsDtq+1xn7PtkAAKiissLgzVOgLijvKpTJYDFadnYOSkpK4OziKBl3dnZCekaWoFSmIT/vPq5e/R3edWqLjmJUmRnZuHzpqmQs5dI1dOv+uqBEYvA8yBg/eOnvS05OxqRJkx4rDABAoVBg0qRJOHXq1DOPo1QqYWdnJ9mMMaXwJAozBSyqWJbnqmqNoK+norS4BJEjvkSJulhIJmMrLi5GUtJpdOwQoB1TKBTo2CEA8fGJApOJp1LZwMvbAxkZmaKjGNWJ+CTUreclGatTzwtpqbfFBBKE54HkqkLFgaurK06cOPHU50+cOAEXF5d/HcpQAqf0R+0XG6JaLUc4N/BA4JT+8GrbCKf3/AplVWsM+XoqLK2V2DNlLZS21qjqZI+qTvZQmD1eDFU2i5euxYjh72Lw4L5o2LAeIpbPg0pljU2bt4uOZlQz53yMdi+1gYdnTbR5sQU2b41AaWkZdu3cLzqaUa1ZsRmt2vhifMgoeHl74q0+3TA4qC82rosUHc2oeB4eUqls4NvMB77NfAAAXl4e8G3mAw8Pd8HJDERTpr/tOVShaYXJkydj1KhRSExMRKdOnbSFQEZGBmJiYrB27VosXLjQIEH1QVXDDm8v+gC2TtVQdP8PZFxMxddDvsDV2LPwatsIHi3qAQAmHV0sed2igAnITavcl7bt3LkXTo4OmDF9MlxdnZCcfA7d3hwku0v63Gu6Ys2GRajuUB13s3NwPD4Rb3Tqi7t374mOZlSnfjuL9waNxyfTJyFkyhjcvJGGaaHzZFck8Tw81KqVL36O3ql9vHDBDADAli07MGJkyFNe9RyT+YJEhUaj0VTkBdu3b8fixYuRmJiI0tLyORlzc3O0atUKISEh6Nev3z8KMt1r4D96XWUz9/Zh0RFMQjUrlegIJsHCTMx0G5mmnD/vi45gMh6o0wx6/KJ4/XVNrdr219uxjKXClzL2798f/fv3R3FxMbKzy/9V6ejoCEtLS72HIyIiEuI5nQ7Ql398h0RLS0u4ucnv5jBERCQDMp9WkO0dEomIiOjJZPXZCkRERH+LzDsHLA6IiIh0yP1TGTmtQERERBLsHBAREenitAIRERFJ8FJGIiIikpB554BrDoiIiEiCnQMiIiJdnFYgIiIiCU4rEBERET3EzgEREZEuTisQERGRBKcViIiIiB5i54CIiEiXzDsHLA6IiIh0yXzNAacViIiISIKdAyIiIl2cViAiIiIJmU8rsDggIiLSJfPOAdccEBERkQQ7B0RERLo4rUBEREQSMp9WMJniYE1ukugIJmGMe4DoCCZhxe1Y0RHIhFiam8yvKqHKNBrREUgm+BNHRESki50DIiIikpB5l4ZXKxAREZEEOwdERES6OK1AREREEjIvDjitQERERBLsHBAREeniTZCIiIhIgtMKREREJKHR6G+rgNLSUkybNg3e3t6wtrZG3bp1MXv2bGgeOY5Go8H06dPh5uYGa2trBAYGIiUlRa/fPosDIiIiE/HFF19g5cqVWL58OS5cuIAvvvgC8+fPx1dffaXdZ/78+Vi2bBlWrVqF48ePQ6VSoXPnzigqKtJbDk4rEBER6RI0rXDs2DH07NkT3bp1AwB4eXnh22+/xYkTJwCUdw2WLFmCzz77DD179gQAbNmyBS4uLtizZw8GDBiglxzsHBAREekqK9PbplarkZ+fL9nUavUTv2y7du0QExODy5cvAwCSk5MRGxuLLl26AACuX7+O9PR0BAYGal9jb28PPz8/xMXF6e3bZ3FARERkQOHh4bC3t5ds4eHhT9x36tSpGDBgABo2bAhLS0u0aNECEydOxMCBAwEA6enpAAAXFxfJ61xcXLTP6QOnFYiIiHTp8VLG0NBQhISESMaUSuUT992xYwe2bt2KyMhING7cGKdOncLEiRPh7u6OoKAgvWV6FhYHREREOjRl+vvgJaVS+dRiQNdHH32k7R4AQNOmTXHjxg2Eh4cjKCgIrq6uAICMjAy4ublpX5eRkYHmzZvrLTOnFYiIiEzEH3/8ATMz6Z9mc3NzlP13gaS3tzdcXV0RExOjfT4/Px/Hjx+Hv7+/3nKwc0BERKRL0NUK3bt3x+effw5PT080btwYv/32GxYtWoT33nsPAKBQKDBx4kTMmTMH9evXh7e3N6ZNmwZ3d3f06tVLbzlYHBAREekSdPvkr776CtOmTcOYMWOQmZkJd3d3vP/++5g+fbp2nylTpqCwsBCjRo1Cbm4uAgICcODAAVhZWekth0KjqeDtmwzEtVoj0RFMQr9qzURHMAkrbseKjkAmxNKc/44BgOLSEtERTEbJg1sGPf4fK8fp7Vg2o7969k4mhj9xREREuvS4IPF5xOKAiIhIl8w/eInFARERkS6ZFwe8lJGIiIgk2DkgIiLSZRpr9YVhcUBERKSL0wry5urmjOWrv8D5a3G4fuc3HPr1B/g2byw6lkG9NqYXPvxhLuaf3YTPT67BiDWT4VzHTbKPrZM9Bi8KxpyE1VhwfjM+2j8Pvm+8KCix8Y3+IAhXLsejIP8qjsXuQ5vWzUVHEkLu52Hy5DGIjd2LzMxzuHEjETt2rEH9+nVExxJG7u8HOZF1cWBvb4d9UZEoKSnBwD6j8ErbNzHjsy+Qm5svOppB1fNrhF++jsKitz5DxODPYW5hjjFbPkUV64f3/h78ZTCc67hjzYj5mNf5IyQfOIFhEZNQq7GXuOBG0rdvDyxcEIbZcxahjd8bSD59Hv/341Y4OdUQHc2oeB6A9u39sGrVFrzySi+8+eYgWFhYYv/+r2FjYy06mtHJ7v1QptHf9hyS9U2QPg0LQRu/FujVdbDRv/bTiLgJUlUHW8xNWoel/Wbg6okLAIAF5zZjx2frkLD7F+1+4b+tw955kYjbftDgmUTeBOlY7D4knEzGhImfASi/Xenv1xIQsWIj5i+IEJbL2EzpPJjKTZAcHR2QmvobAgP74tdfTxj964u8CZIpvR8AI9wEacF7ejuWzUcb9HYsY5F156Bzlw5IPnUOazctxtmUWEQf/R4Dh/QVHcvorGxtAAB/5BZox64nXkKLN/1hY6+CQqFAy+7tYKG0REr8OVExjcLS0hItWzZDzMGHRZFGo0HMwVi0bdtKYDLj4nl4Mjs7WwDAvXu5YoMYGd8P8qP34iA1NVX7ARFPo1arkZ+fL9k0Au5j7enlgaD3BuDa1RsY0HskNq/fhjlffIJ+7/Q0ehZRFAoF3p4ehKsJF3Hncqp2fOPYJTC3tMC85A1YdPkb9P98JNa//yWyb2QITGt4jo4OsLCwQGZGtmQ8MzMLri5OglIZH8/D4xQKBRYsCMOxYwk4f/6y6DhGJcv3g8ynFfReHOTk5GDz5s1/uU94eDjs7e0lW6H6rr6jPJOZmQJnks8jfPYSnD19Ad9s3omtW3ZiyLABRs8iSt/Z78GtgQc2j1sqGe8a0h/WdjZY/u5sLOjxCQ6t/xFDIybCrYGHoKREYi1ZMhuNG7+AIUPGio5CRqApK9Pb9jyq8ETe3r17//L5a9euPfMYoaGhCAkJkYzV92hT0Sj/WmZGNi5fuioZS7l0Dd26v270LCL0mTkMjTu2xNJ+M5CbnqMdd/R0wStD38Dc1z5EekoaAOD2hRuo26Yh2g/pjB2frhMV2eCys3NQUlICZxdHybizsxPSM7IEpTI+ngepxYtnoWvXTggM7Idbt9JFxzE6vh/kp8LFQa9evaBQKPBX6xgVCsVfHkOpVEKpVErGFArjL384EZ+EuvW8JGN16nkhLfW20bMYW5+Zw9Cs84v4asBM5KRJf7gtrasAADQ67bCysrJn/n/7vCsuLkZS0ml07BCAvXujAJS/nzt2CMCKlRsFpzMenoeHFi+ehR49OuP11/vjxo3UZ7+gEpLl++E5nQ7Qlwr/RXZzc8OuXbtQVlb2xC0pKckQOQ1izYrNaNXGF+NDRsHL2xNv9emGwUF9sXFdpOhoBtV39nC0fqs9tkxYhqLCP2HrZA9bJ3tYKi0BABlXbyPz+h30nzsSnr514ejpgg4j3kSDgKY4858EwekNb/HStRgx/F0MHtwXDRvWQ8TyeVCprLFp83bR0YyK5wFYsmQOBgzohaCg8SgoKISLixNcXJxgZaV89osrGdm9HzRl+tueQxXuHLRq1QqJiYno2fPJi/ae1VUwJad+O4v3Bo3HJ9MnIWTKGNy8kYZpofOwa+d+0dEMqv3g8mmT8dtnSMa/mbwCJ747grKSUqweNg/dP34Xo9ZNgVJlhewbGdj64QqcP3zK+IGNbOfOvXBydMCM6ZPh6uqE5ORz6PbmIGRmZj/7xZUIzwPw/vvllzlHR++QjI8c+SG++eY7EZGEkd37Qeadgwrf5+CXX35BYWEh3njjjSc+X1hYiJMnT+KVV16pUBAR9zkwRSLuc2CKRN7ngEyPqdznQDSR9zkwNYa+z0HhrIF6O5Zq+la9HctYKvwT1759+798XqVSVbgwICIiMinP6VUG+sJynIiISJfMpxVkfYdEIiIiehw7B0RERLqe06sM9IXFARERkS5OKxARERE9xM4BERGRjuf1MxH0hcUBERGRLk4rEBERET3EzgEREZEumXcOWBwQERHp4qWMREREJCHzzgHXHBAREZEEOwdEREQ6NDLvHLA4ICIi0iXz4oDTCkRERCTBzgEREZEu3iGRiIiIJDitQERERPQQOwdERES6ZN45YHFARESkQ6ORd3HAaQUiIiKSYOeAiIhIF6cViIiISILFARERET2Kt082EeYKLn8AgAOFV0VHMAmj3F8SHcEkfJudJDqCSSgsLhIdwSSYKRSiI5BMmExxQEREZDLYOSAiIiIJed89mZcyEhERkRQ7B0RERDq4IJGIiIikZF4ccFqBiIiIJNg5ICIi0iXzBYksDoiIiHTIfc0BpxWIiIhIgp0DIiIiXZxWICIiokfJfVqBxQEREZEumXcOuOaAiIiIJNg5ICIi0qGReeeAxQEREZEumRcHnFYgIiIiCXYOiIiIdHBagYiIiKRkXhxwWoGIiIgk2DkgIiLSIfdpBXYOiIiIdGjK9LdV1K1btzBo0CDUqFED1tbWaNq0KU6ePPkwm0aD6dOnw83NDdbW1ggMDERKSooev3sWB0RERI8RVRzcu3cPL730EiwtLfHTTz/h/Pnz+PLLL1G9enXtPvPnz8eyZcuwatUqHD9+HCqVCp07d0ZRUZHevn9OKxAREZmIL774Ah4eHti4caN2zNvbW/vfGo0GS5YswWeffYaePXsCALZs2QIXFxfs2bMHAwYM0EsOdg6IiIh0aRR629RqNfLz8yWbWq1+4pfdu3cvWrdujb59+8LZ2RktWrTA2rVrtc9fv34d6enpCAwM1I7Z29vDz88PcXFxevv2ZV8cxCf/B7funXts+3zBZ6KjGVRr/xZY9c0i/HLmJ1zOOonALq88ts/4j99H7NkDOH0zFpu+i0DtOh4CkhpO5zG98PEPc7Ho7GZ8cXIt3l/zEZzruGmfd6jlhBW/73ji1qJrW4HJjW9iyPu4V3AFc7/4VHQUowoI8MPuXRvx+/WTeKBOQ48enUVHEkZu50Kf0wrh4eGwt7eXbOHh4U/8uteuXcPKlStRv359REVFYfTo0Rg/fjw2b94MAEhPTwcAuLi4SF7n4uKifU4fZD+t0LVjf5ibm2sfN2xUD9v2rMf+PVECUxmejY01Lp5LwfeRexGxeeFjz48cF4QhIwfg47EzkHbzFiZMHY0N279Cl4B+eKB+ICCx/tXz88GRr6NwI/kqzCzM0fOjdzBuy2eY/VoIHvypxr3b2ZjaZqTkNS+9E4jXRvXA+cO/CUptfC1aNsXQ9wbg7JkLoqMYnUplg9Onz2PTpu3YuXOd6DhC8Vz8c6GhoQgJCZGMKZXKJ+5bVlaG1q1bY+7cuQCAFi1a4OzZs1i1ahWCgoIMnvV/ZF8c5Ny9J3k8duIIXL92E3G/JghKZBxHY47haMyxpz4f9P47WLFoPWIOHAEATAmejrjz/8FrXV7Fj3v+Y6yYBhURNFfyeMvkCMxPWg/PpnVw5cQFaMo0yM/Kk+zTvPOLSPoxDuo/ntwSrGxUKhusWb8IE8Z+iskfB4uOY3RRUYcQFXVIdAyTILdzoSlT6O1YSqXyqcWALjc3N/j4+EjGGjVqhO+//x4A4OrqCgDIyMiAm9vDTmdGRgaaN2+un8DgtIKEpaUl3u73JrZv3SU6ilAetWvC2cURcUdPaMcK7hciOeksmrdpKjCZYVnb2gAACnMLnvi8RxNveDT2xrHtB40ZS6gFi2bgP1GHceTw0wtJospI1NUKL730Ei5duiQZu3z5MmrXrg2gfHGiq6srYmJitM/n5+fj+PHj8Pf3/9ff9//IvnPwqDe6dYSdvS12RO4RHUUoR+caAIDsrLuS8eysHDj997nKRqFQoM/0obiScBF3Lqc+cZ+X+nfEnZQ0XEu6bOR0Yrzdpxt8mzdGx5ffEh2FSDYmTZqEdu3aYe7cuejXrx9OnDiBNWvWYM2aNQDKf1dNnDgRc+bMQf369eHt7Y1p06bB3d0dvXr10luOChcHf/75JxITE+Hg4PBY66OoqAg7duzAkCFD/vIYarX6sZWaGk0ZFAqxjYwBg3rj0M+xyEjPEpqDjK//7OFwb+CBL/tMf+LzlkpLtO4ZgJ+WfW/kZGLUrOmG8PnT8Hb3IKgryRoToorQaPQ3rVARbdq0we7duxEaGopZs2bB29sbS5YswcCBA7X7TJkyBYWFhRg1ahRyc3MREBCAAwcOwMrKSm85KvTX+PLly2jUqBFefvllNG3aFK+88gru3LmjfT4vLw/Dhg175nGetHLzflF2xdPrUU0PN7R/tS0it3wnNIcpyM4s7xg4Okm7BI5ODsjKvPuklzzX+s18D007tsSSATORm57zxH1adG2LKlZKHN91xMjpxPBt0RjOzo44/OsPyMq9iKzciwho74f3RwchK/cizMw4I0mVm8g7JL755ps4c+YMioqKcOHCBYwcKV0YrVAoMGvWLKSnp6OoqAg///wzXnjhBT195+Uq9BP+8ccfo0mTJsjMzMSlS5dga2uLl156CTdv3qzQFw0NDUVeXp5ks7VyrNAx9K3/u28hOysHMf85KjSHKUi9cQuZGdnwb99GO6aqqoJvyyY4lXBGYDL96zfzPTTv/CKWvDsLd9Oe3jFq178jTv98EgU5942YTpyjh+PQ7sUueLldd+2WlHgaO7fvxcvtuqOsTOY3nieq5Co0rXDs2DH8/PPPcHR0hKOjI/bt24cxY8agffv2OHToEFQq1d86zpNWboqcUlAoFOg/8C3s3PYDSktLheUwJhuVNWp7P7xvQS3PmmjU5AXk3svDnVsZ2Lz6W4wOGY7fr6Ui7eYtTJw6GpnpWYj+6bC40Ho2YPZwtO4ZgNUj50Nd+CfsnOwBAH/m/4FidbF2P6faLqj3YiOsGPbk65Iro4KCQlw4L71X+x9//ImcnHuPjVdmKpUN6tX10j728vKAbzMf5NzLRWrqbXHBBJDbudDn1QrPowoVB3/++ScsLB6+RKFQYOXKlRg7dixeeeUVREZG6j2gMbR/1R+1PNyx/Rv5XKXQxNcH3/ywWvv4kznl1+Du2rYPU8fNxNqvNsPaxgqzF30COztbJB4/heH9x1eaexwAwMuDy2/iMmn7TMn4lskRiP/u4fSBf7+OyL2TgwtHTxs1H4nXqpUvfo7eqX28cMEMAMCWLTswYmTIU15VOcntXGg0ohOIpdBo/v4pePHFFzFu3DgMHjz4sefGjh2LrVu3Ij8//x/967tm9cYVfk1lpLKwFh3BJASq6oiOYBK+zU4SHcEkFBbr7wNlqHJ4oE4z6PFvtAx89k5/U+2kn/V2LGOpUC//rbfewrfffvvE55YvX4533nkHFag1iIiIyARVqHNgSOwclGPnoBw7B+XYOSjHzgHpMnTn4Pfmr+ntWF6novV2LGPhTZCIiIh0mMY/m8XhxcpEREQkwc4BERGRDl7KSERERBKibp9sKjitQERERBLsHBAREen4J5+JUJmwOCAiItJRxmkFIiIioofYOSAiItIh9wWJLA6IiIh08FJGIiIikuAdEomIiIgewc4BERGRDk4rEBERkQQvZSQiIiJ6BDsHREREOngpIxEREUnwagUiIiKiR7BzQEREpEPuCxJZHBAREemQ+5oDTisQERGRBDsHREREOuS+IJHFARERkQ6uOTARWX/kiY5gEjI0uaIjmIR1+emiI5iEQW5tRUcwCd/ciRcdwSSUyf2fs0bENQdEREREjzCZzgEREZGp4LQCERERSch9AofTCkRERCTBzgEREZEOTisQERGRBK9WICIiInoEOwdEREQ6ykQHEIzFARERkQ4NOK1AREREpMXOARERkY4ymd/ogMUBERGRjjKZTyuwOCAiItLBNQdEREREj2DngIiISAcvZSQiIiIJTisQERERPYKdAyIiIh2cViAiIiIJuRcHnFYgIiIiCXYOiIiIdMh9QSKLAyIiIh1l8q4NOK1AREREUuwcEBER6eBnKxAREZGEzD+UkdMKAQF+2L1rI36/fhIP1Gno0aOz6EjCjP4gCFcux6Mg/yqOxe5Dm9bNRUcyOjm+H7qOeQvTfpiHFWe/xpKT6zF2zRS41nGX7DNl20xs+P07yTb481GCEhuPHN8Pf0VOvyPK9Lg9j2RfHKhUNjh9+jwmTPhMdBSh+vbtgYULwjB7ziK08XsDyafP4/9+3AonpxqioxmVHN8PDfx8cPDrA5jzVii+HDwL5hbmCNkyDVWslZL9jkRGY2KbEdptZ/jXghIbjxzfD0/D3xHyIvtphaioQ4iKOiQ6hnCTJozEuvWR2LxlBwBgTPBUdO3SCcOGDsD8BRGC0xmPHN8Pi4M+lzzeMDkCS5M2wKtpHVw+cUE7/qBIjfysXCOnE0uO74enkdvviDKFvNccyL5zQIClpSVatmyGmIO/aMc0Gg1iDsaibdtWApORCNa2NgCAwtwCyXjbnu2xNGkDZkUtQu8p76KKVRUR8UgAOf6O0Ohxex5VuHNw4cIFxMfHw9/fHw0bNsTFixexdOlSqNVqDBo0CB07dnzmMdRqNdRqtWRMo9FAIfNKTRRHRwdYWFggMyNbMp6ZmYWGDeoKSkUiKBQKvDN9GFISLuDW5VTt+PEffkH2rSzkZtyDR8Pa6DN1EFzr1ETEBwsEpiVj4e8I+alQcXDgwAH07NkTVatWxR9//IHdu3djyJAh8PX1RVlZGV5//XX85z//eWaBEB4ejpkzZ0rGzMxsYW5hV/HvgIj0ZtDsEajZwAPhfaRz7Ee+/Vn737cu3URu5j1M+XYGnDxdkHUzw9gxiQzueV1IqC8VmlaYNWsWPvroI9y9excbN27Eu+++i5EjRyI6OhoxMTH46KOPMG/evGceJzQ0FHl5eZLNzNz2H38T9O9kZ+egpKQEzi6OknFnZyekZ2QJSkXGNnDmcPh2bIX5A2bgXnrOX+577VQKAMDZy9UY0UgwOf6OKFPob3seVag4OHfuHIYOHQoA6NevH+7fv48+ffponx84cCBOnz79zOMolUrY2dlJNk4piFNcXIykpNPo2CFAO6ZQKNCxQwDi4xMFJiNjGThzOFp2fhHz352B7LTMZ+7v6eMFAMjLzDVsMDIJ/B0hPxVekPi/P+JmZmawsrKCvb299jlbW1vk5eXpL50RqFQ28G3mA99mPgAALy8P+DbzgYeH+zNeWbksXroWI4a/i8GD+6Jhw3qIWD4PKpU1Nm3eLjqaUcnx/TBo9gj4v/UyVk9YiqLCItg5VYOdUzVYKssXHDp5uqD7uD6o3aQOatRyQvPA1hixaBwuHT+HtIs3BKc3LDm+H55Gbr8jyqDQ2/ZPzZs3DwqFAhMnTtSOFRUVITg4GDVq1EDVqlXRu3dvZGTof2qvQmsOvLy8kJKSgrp1yxegxMXFwdPTU/v8zZs34ebmpt+EBtaqlS9+jt6pfbxwwQwAwJYtOzBiZIigVMa3c+deODk6YMb0yXB1dUJy8jl0e3MQMjOzn/3iSkSO74eOg98AAEzdPksyvn7ycvz63WGUFJfAJ6ApXnuvG5Q2SuTcvovEn+Kxb/n3IuIalRzfD08jt98Roq8ySEhIwOrVq9GsWTPJ+KRJk/Djjz9i586dsLe3x9ixY/H222/j119/1evXV2g0mr99DlatWgUPDw9069btic9/8sknyMzMxLp16yocpIqyVoVfUxmV/f3/Oyo1M04zAQAGubUVHcEkfHMnXnQEk8DfDw+VPLhl0ON/4z5Ib8fqe339Y1foKZVKKJXKJ+5fUFCAli1bYsWKFZgzZw6aN2+OJUuWIC8vD05OToiMjNRO6V+8eBGNGjVCXFwc2rbV3++LCk0rfPDBB08tDABg7ty5/6gwICIiMiX6XJAYHh4Oe3t7yRYeHv7Urx0cHIxu3bohMDBQMp6YmIji4mLJeMOGDeHp6Ym4uDi9fv+yv0MiERGRLn1eyhgaGoqQEOk01NO6Btu2bUNSUhISEhIeey49PR1VqlRBtWrVJOMuLi5IT0/XW16AxQEREdFj9DmB81dTCI9KTU3FhAkTEB0dDSsrKz0mqDjePpmIiMgEJCYmIjMzEy1btoSFhQUsLCxw5MgRLFu2DBYWFnBxccGDBw+Qm5sreV1GRgZcXfV7zxF2DoiIiHSIuHlRp06dcObMGcnYsGHD0LBhQ3z88cfw8PCApaUlYmJi0Lt3bwDApUuXcPPmTfj7++s1C4sDIiIiHSJun2xra4smTZpIxlQqFWrUqKEdHz58OEJCQuDg4AA7OzuMGzcO/v7+er1SAWBxQERE9NxYvHgxzMzM0Lt3b6jVanTu3BkrVqzQ+9dhcUBERKTDVD546fDhw5LHVlZWiIiIQEREhEG/LosDIiIiHRqZ34eNVysQERGRBDsHREREOkxlWkEUFgdEREQ65F4ccFqBiIiIJNg5ICIi0iH3z79kcUBERKRDxB0STQmLAyIiIh1cc0BERET0CHYOiIiIdMi9c8DigIiISIfcFyRyWoGIiIgk2DkgIiLSwasViIiISELuaw44rUBEREQS7BwQERHpkPuCRBYHREREOspkXh6wODAxlub8vwQAVJZK0RFMwpbbcaIjmIQ5bh1ERzAJKwtOi45AMsG/RERERDrkviCRxQEREZEOeU8qsDggIiJ6jNw7B7yUkYiIiCTYOSAiItLBOyQSERGRhNwvZeS0AhEREUmwc0BERKRD3n0DFgdERESP4dUKRERERI9g54CIiEiH3BcksjggIiLSIe/SgNMKREREpIOdAyIiIh1yX5DI4oCIiEgH1xwQERGRhLxLA645ICIiIh3sHBAREengmgMiIiKS0Mh8YoHTCkRERCTBzgEREZEOTisQERGRhNwvZeS0AhEREUmwc0BERKRD3n0DFgdERESP4bSCzAUE+GH3ro34/fpJPFCnoUePzqIjCTF58hjExu5FZuY53LiRiB071qB+/TqiYxndlNBxyM6/LNniTh4QHUuY0R8E4crleBTkX8Wx2H1o07q56EgG1WJQJ7x3YC4mnV2LSWfXYvDuMNR5tdkT9+27+SNMvfEN6r/eysgpjc/MzAwfhgYjNuknXEo7gaMnf8T4D0eJjkUGJPvOgUplg9Onz2PTpu3YuXOd6DjCtG/vh1WrtiAxMRkWFhaYOXMK9u//Gi1aBOKPP/4UHc+oLpy/jN49hmofl5SUigsjUN++PbBwQRjGBE/FiYTfMH7cCPzfj1vh0+RlZGXdFR3PIO7fycHhL7bj3vV0QKFA0z7t0XttCDZ2/RTZKbe0+7UZ/gagkc+/LEdPeA+DhvXDh8Gf4fLFq2jWvDEWLJ+F/PsF2LQmUnQ8g+DVCnqg0WigUCj0cSiji4o6hKioQ6JjCNezZ5Dk8ahRHyI19Te0aNEUv/56QlAqMUpKSpGZmS06hnCTJozEuvWR2LxlBwBgTPBUdO3SCcOGDsD8BRGC0xnGlZjfJI+PLtiJFoM6wb1lPW1x4OzjiTYju2Jz92kYd7Jyngddrdr4IvqnQzgY/QsAIC31Nnr07oLmLZsITmY4vAmSHiiVSly4cEEfhyITYWdnCwC4dy9XbBAB6tStjbOXfsHJ5BisWrcQNWu5iY5kdJaWlmjZshliDv6iHdNoNIg5GIu2bSt/Gx0AFGYKNOreFpbWStxKSgEAWFhVQY9lwYietgmFWXmCExpPYkIy2r3sB++6tQEAjRq/gNZ+LXD451jByQynTI/b86hCnYOQkJAnjpeWlmLevHmoUaMGAGDRokV/eRy1Wg21Wi0Ze567D5WNQqHAggVhOHYsAefPXxYdx6gSTyZj3OipuJJyHS6uTvho6ljsPxCJ9m3fREFBoeh4RuPo6AALCwtkZkg7KJmZWWjYoK6gVMbh1KAWBu+eAQulJR4UFmHX+0twN+U2AKDT9EG4lZiClOgkwSmNa8WS9ahqq8LB+B9QWloKc3NzLPj8K+z57v9ERyMDqVBxsGTJEvj6+qJatWqScY1GgwsXLkClUv2tP/Dh4eGYOXOmZMzMzBbmFnYViUMGsmTJbDRu/AI6deojOorRxUQf1f73+XOXkHgyGafOHkbPt7pg69ffCUxGxnL32h1s6PIplLbWaNj1Rbz55fvY2n8Oqtd2Re12PtjY9VPREY3uzV6d0atPN4wfNRWXL16FT9MGCPt8CjLSs/D9tr2i4xmE3KcVKlQczJ07F2vWrMGXX36Jjh07asctLS2xadMm+Pj4/K3jhIaGPtaFqOHYqCJRyEAWL56Frl07ITCwH27dShcdR7j8vPu4evV3eNepLTqKUWVn56CkpATOLo6ScWdnJ6RnZAlKZRxlxaXIvZEBAMg4+zvcfOug9bA3UFL0ANVrO2PSmTWS/d9aNQFpJy4hcsDnIuIaxSczQ7By6Xrs211+5c6lCymo5eGGMROHV9ri4HmdDtCXChUHU6dORadOnTBo0CB0794d4eHhsLS0rPAXVSqVUCqVkjFOKYi3ePEs9OjRGa+/3h83bqSKjmMSVCobeHl7YMe2TNFRjKq4uBhJSafRsUMA9u6NAlD+M9qxQwBWrNwoOJ1xKcwUsKhigdjF3yN522HJcyOi5yFm1jePLWSsbKytrVBWJv2XdGlpGcz4e7vSqvDVCm3atEFiYiKCg4PRunVrbN269bn+w65S2aBeXS/tYy8vD/g280HOvVykpt4WF8zIliyZg/79e6Bv35EoKCiEi4sTACAvLx9FRepnvLrymDnnY0T9dBCpqbfh6uqMjz8Zj9LSMuzauV90NKNbvHQtNq5fjMSk00hI+A3jx42ESmWNTZu3i45mMK9M6Ydrh5ORf/suqqis4NOzHTzbNsL2wfNRmJX3xEWI+bfvIi+1cndTfo46grEhI3E77Q4uX7yKxs0aYsTowdgRuUd0NIMpk9Glqk/yjy5lrFq1KjZv3oxt27YhMDAQpaXP73XgrVr54ufondrHCxfMAABs2bIDI0Y+eQFmZfT++4MBANHROyTjI0d+iG++kc9cu3tNV6zZsAjVHarjbnYOjscn4o1OfXH37j3R0Yxu5869cHJ0wIzpk+Hq6oTk5HPo9uagSn2Zp42jHd5c9AFUztWgvv8Hsi6mYvvg+fg99qzoaEKFTQ3Hh6FjMXvBp3B0dEBGehYiN3+HpQtWiY5mMPIuDQCFRvPvyqO0tDQkJiYiMDAQKpXqHx+nirLWv4lRaZibmYuOYBJUlspn7yQDuUXyuULir8xx6yA6gklYWXBadASTceOuYc/FoNpv6+1Y39zYpbdjGcu/vglSrVq1UKsW/7ATEVHlIffPVpD97ZOJiIh0yf1SRtl/8BIRERFJsXNARESkg/c5ICIiIgmuOSAiIiIJrjkgIiIiegQ7B0RERDq45oCIiIgk/uX9AZ97nFYgIiIyEeHh4WjTpg1sbW3h7OyMXr164dKlS5J9ioqKEBwcjBo1aqBq1aro3bs3MjIy9JqDxQEREZGOMmj0tlXEkSNHEBwcjPj4eERHR6O4uBivv/46Cgsf3kp90qRJ2LdvH3bu3IkjR47g9u3bePtt/d3uGeC0AhER0WP0ueZArVZDrZZ+uq1SqYRS+fhnyBw4cEDyeNOmTXB2dkZiYiJefvll5OXlYf369YiMjETHjh0BABs3bkSjRo0QHx+Ptm3b6iUzOwdEREQGFB4eDnt7e8kWHh7+t16bl1f+MeEODg4AgMTERBQXFyMwMFC7T8OGDeHp6Ym4uDi9ZWbngIiISIc+73MQGhqKkJAQydiTuga6ysrKMHHiRLz00kto0qQJACA9PR1VqlRBtWrVJPu6uLggPT1db5lZHBAREenQ5x0SnzaF8CzBwcE4e/YsYmNj9Zbl7+K0AhERkYkZO3Ys9u/fj0OHDqFWrVracVdXVzx48AC5ubmS/TMyMuDq6qq3r8/igIiISIdGo9HbVtGvO3bsWOzevRsHDx6Et7e35PlWrVrB0tISMTEx2rFLly7h5s2b8Pf318v3DnBagYiI6DGi7pAYHByMyMhI/PDDD7C1tdWuI7C3t4e1tTXs7e0xfPhwhISEwMHBAXZ2dhg3bhz8/f31dqUCwOKAiIjoMaI+eGnlypUAgFdffVUyvnHjRgwdOhQAsHjxYpiZmaF3795Qq9Xo3LkzVqxYodccLA6IiIhMxN+ZhrCyskJERAQiIiIMloPFARERkQ59Xq3wPGJxQEREpIMfvERERET0CHYOiIiIdHBagYiIiCREXa1gKlgcmJjSslLREUxCI1sP0RFMQlzRRdERTML09MOiI5iEhtX5c0HGweKAiIhIR5nMFySyOCAiItIh79KAVysQERGRDnYOiIiIdPBqBSIiIpJgcUBEREQSvEMiERER0SPYOSAiItLBaQUiIiKSkPsdEjmtQERERBLsHBAREemQ+4JEFgdEREQ65L7mgNMKREREJMHOARERkQ5OKxAREZEEpxWIiIiIHsHOARERkQ653+eAxQEREZGOMq45ICIiokfJvXPANQdEREQkwc4BERGRDk4rEBERkQSnFYiIiIgewc4BERGRDrlPK8i+cxAQ4Ifduzbi9+sn8UCdhh49OouOJIRcz4OvX1PM2zQHuxO345dbMWjf+aXH9qldzxPhG2fjpws/4D8p+7Hmxwg4uzsLSGt8oz8IwpXL8SjIv4pjsfvQpnVz0ZGMSq4/F63aNsdXWxbg51N7cTo9Dh3eeFn7nIWFOSZ+NgbfH/oGx68dxM+n9uLzr6bDycVRYGL90+jxf88j2RcHKpUNTp8+jwkTPhMdRSi5ngcrG2tcOX8Viz5d9sTn3Wu7IWLPUty8korxfT7E0MCR2LzkGzxQPzByUuPr27cHFi4Iw+w5i9DG7w0knz6P//txK5ycaoiOZjRy/bmwtrHCpXMpmBv65WPPWVlboVHTBli9eCP6vzYUIe+FwquuJ5ZtmS8gKRmK7KcVoqIOISrqkOgYwsn1PBw/dALHD5146vOjPh6O+IPHsfLzNdqx2zfuGCOacJMmjMS69ZHYvGUHAGBM8FR07dIJw4YOwPwFEYLTGYdcfy5iD8Yj9mD8E58ruF+I9/tPkIzN/eRLfHtgA1xruiD9VoYxIhocpxWI6IkUCgX8O/kh9Voavtw6D3uTv8PqfcufOPVQ2VhaWqJly2aIOfiLdkyj0SDmYCzatm0lMBmZoqq2VVFWVob7efdFR9EbTisIoFarkZ+fL9nk/vGYZHqqO1aDTVUbDAwegOOHExDy7sc4eiAWc9bNQPO2zUTHMyhHRwdYWFggMyNbMp6ZmQVXFydBqcgUVVFWwaTPxuCn3dEoLPhDdBzSk381rVBYWIgdO3bgypUrcHNzwzvvvIMaNZ49HxkeHo6ZM2dKxszMbGFuYfdv4hDplcKsvHaOjTqGHWu/BwBcOXcVTVo3Rs/B3XEq/rTIeETCWViYY+GaOVAoFJjzceVac6DRlImOIFSFOgc+Pj7IyckBAKSmpqJJkyaYNGkSoqOjERYWBh8fH1y/fv2ZxwkNDUVeXp5kMzO3/WffAZGB5OXkoaS4BL+n3JCM30i5CZealftqhezsHJSUlMBZZwW6s7MT0jOyBKUiU2JhYY4Faz6HWy1XjOo/vtJ1Dcqg0dv2PKpQcXDx4kWUlJQAKP8D7+7ujhs3buDEiRO4ceMGmjVrhk8//fSZx1EqlbCzs5NsCoXin30HRAZSUlyCC8mX4FnXQzLuUacW0tMqx6KrpykuLkZS0ml07BCgHVMoFOjYIQDx8YkCk5Ep+F9hULtOLYzqNx559/JFR9I7jUajt+159I+nFeLi4rBq1SrY29sDAKpWrYqZM2diwIABegtnDCqVDerV9dI+9vLygG8zH+Tcy0Vq6m1xwYxMrufB2sYKNb1rah+7ebqiXuO6yL93H5m3M/Htyu2YuXIakuNPI+nYKfi92gbtXvPH+D4hAlMbx+Kla7Fx/WIkJp1GQsJvGD9uJFQqa2zavF10NKOR78+FNTy9a2kf1/R0R4PG9ZGXm4/sjGx8uW4uGjVtgLGDJ8PMzAw1nBwAAHm5+SgpLhEVm/RIoalAWWNmZoaMjAw4OTmhZs2aiIqKQpMmTbTP37hxAw0bNsSff/5Z4SBVlLWevZMBvPyyP36O3vnY+JYtOzBiZOX/A/A/pnYe/BwbGOXrNPf3xVffLXps/KcdUZg7qXwOtWv/NzBo3DtwdnXCzWup2LBwM2L/c8wo+eKyLhrl6zzNmNFD8WHIaLi6OiE5+RwmTpqOEwm/GT2HmaDOoqn9XDSs7vHsnfSgdbsW2LBrxWPjP2z/ESsXrsOBhN1PfN17b4/ByWPGeX+cTo8z6PFrOTR59k5/U1rOWb0dy1gqXBw0adIEFhYWSElJwaZNm9C7d2/t80ePHsW7776LtLS0CgcRVRyQaTJWcWDqRBcHpkJUcWBqjFUcPA8MXRzUrN5Yb8e6de+c3o5lLBWaVggLC5M8rlq1quTxvn370L59+3+fioiIiISpUOfAkNg5oEexc1COnYNy7ByUY+fgIUN3Dtyq+ejtWHdyz+vtWMYi+9snExER6Xpe72yoL7x9MhEREUmwc0BERKTDRGbchWFxQEREpON5vbOhvnBagYiIiCTYOSAiItLBaQUiIiKSKGNxQERERI+Se+eAaw6IiIhIgp0DIiIiHXK/WoHFARERkQ5OKxARERE9gp0DIiIiHbxagYiIiCT4wUtEREREj2DngIiISAenFYiIiEiCVysQERERPYKdAyIiIh1yX5DI4oCIiEgHpxWIiIhIQqPR6G2rqIiICHh5ecHKygp+fn44ceKEAb7Dv8bigIiIyERs374dISEhCAsLQ1JSEnx9fdG5c2dkZmYaNQeLAyIiIh0aPW5qtRr5+fmSTa1WP/HrLlq0CCNHjsSwYcPg4+ODVatWwcbGBhs2bDDkt/s4DWk0Go2mqKhIExYWpikqKhIdRSieh3I8D+V4HsrxPJTjefhnwsLCHqsZwsLCHttPrVZrzM3NNbt375aMDxkyRNOjRw/jhP0vhUYj81UX/5Wfnw97e3vk5eXBzs5OdBxheB7K8TyU43kox/NQjufhn1Gr1Y91CpRKJZRKpWTs9u3bqFmzJo4dOwZ/f3/t+JQpU3DkyBEcP37cKHkBXq1ARERkUE8qBEwd1xwQERGZAEdHR5ibmyMjI0MynpGRAVdXV6NmYXFARERkAqpUqYJWrVohJiZGO1ZWVoaYmBjJNIMxcFrhv5RKJcLCwp671o++8TyU43kox/NQjuehHM+D4YWEhCAoKAitW7fGiy++iCVLlqCwsBDDhg0zag4uSCQiIjIhy5cvx4IFC5Ceno7mzZtj2bJl8PPzM2oGFgdEREQkwTUHREREJMHigIiIiCRYHBAREZEEiwMiIiKSYHEA0/h4TNGOHj2K7t27w93dHQqFAnv27BEdSYjw8HC0adMGtra2cHZ2Rq9evXDp0iXRsYxu5cqVaNasGezs7GBnZwd/f3/89NNPomMJN2/ePCgUCkycOFF0FKOaMWMGFAqFZGvYsKHoWGRAsi8OTOXjMUUrLCyEr68vIiIiREcR6siRIwgODkZ8fDyio6NRXFyM119/HYWFhaKjGVWtWrUwb948JCYm4uTJk+jYsSN69uyJc+fOiY4mTEJCAlavXo1mzZqJjiJE48aNcefOHe0WGxsrOhIZklE/5skEvfjii5rg4GDt49LSUo27u7smPDxcYCqxADz2qWBylZmZqQGgOXLkiOgowlWvXl2zbt060TGEuH//vqZ+/fqa6OhozSuvvKKZMGGC6EhGFRYWpvH19RUdg4xI1p2DBw8eIDExEYGBgdoxMzMzBAYGIi4uTmAyMhV5eXkAAAcHB8FJxCktLcW2bdtQWFho9Fu4morg4GB069ZN8rtCblJSUuDu7o46depg4MCBuHnzpuhIZECyvn1ydnY2SktL4eLiIhl3cXHBxYsXBaUiU1FWVoaJEyfipZdeQpMmTUTHMbozZ87A398fRUVFqFq1Knbv3g0fHx/RsYxu27ZtSEpKQkJCgugowvj5+WHTpk1o0KAB7ty5g5kzZ6J9+/Y4e/YsbG1tRccjA5B1cUD0V4KDg3H27FnZzq02aNAAp06dQl5eHr777jsEBQXhyJEjsioQUlNTMWHCBERHR8PKykp0HGG6dOmi/e9mzZrBz88PtWvXxo4dOzB8+HCBychQZF0cmNLHY5JpGTt2LPbv34+jR4+iVq1aouMIUaVKFdSrVw8A0KpVKyQkJGDp0qVYvXq14GTGk5iYiMzMTLRs2VI7VlpaiqNHj2L58uVQq9UwNzcXmFCMatWq4YUXXsCVK1dERyEDkfWaA1P6eEwyDRqNBmPHjsXu3btx8OBBeHt7i45kMsrKyqBWq0XHMKpOnTrhzJkzOHXqlHZr3bo1Bg4ciFOnTsmyMACAgoICXL16FW5ubqKjkIHIunMAmM7HY4pWUFAg+VfA9evXcerUKTg4OMDT01NgMuMKDg5GZGQkfvjhB9ja2iI9PR0AYG9vD2tra8HpjCc0NBRdunSBp6cn7t+/j8jISBw+fBhRUVGioxmVra3tY+tNVCoVatSoIat1KJMnT0b37t1Ru3Zt3L59G2FhYTA3N8c777wjOhoZiOyLg/79+yMrKwvTp0/XfjzmgQMHHlukWNmdPHkSHTp00D4OCQkBAAQFBWHTpk2CUhnfypUrAQCvvvqqZHzjxo0YOnSo8QMJkpmZiSFDhuDOnTuwt7dHs2bNEBUVhddee010NBIgLS0N77zzDu7evQsnJycEBAQgPj4eTk5OoqORgfAjm4mIiEhC1msOiIiI6HEsDoiIiEiCxQERERFJsDggIiIiCRYHREREJMHigIiIiCRYHBAREZEEiwMiIiKSYHFAREREEiwOiIiISILFAREREUn8P6zwjwL9degcAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(classification_report(np.argmax(Y_test,1),np.argmax(preds,1)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXJ_YDu8k0m_",
    "outputId": "c4a8e772-0028-433b-c151-4b506df82f7d"
   },
   "id": "WXJ_YDu8k0m_",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8/8 [==============================] - 6s 696ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71        50\n",
      "           1       0.70      0.83      0.76        36\n",
      "           2       0.42      0.60      0.50        50\n",
      "           3       0.75      0.75      0.75        28\n",
      "           4       0.81      0.70      0.75        50\n",
      "           5       0.71      0.39      0.50        31\n",
      "\n",
      "    accuracy                           0.66       245\n",
      "   macro avg       0.69      0.66      0.66       245\n",
      "weighted avg       0.69      0.66      0.66       245\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "colab": {
   "provenance": [],
   "gpuType": "V28",
   "include_colab_link": true
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
